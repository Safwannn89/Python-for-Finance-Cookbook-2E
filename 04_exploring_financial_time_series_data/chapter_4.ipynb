{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OEACZptdHC7"
   },
   "source": [
    "Please run those two cells before running the Notebook!\n",
    "\n",
    "As those plotting settings are standard throughout the book, we do not show them in the book every time we plot something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:48:06.120195Z",
     "start_time": "2020-01-29T10:48:05.814125Z"
    },
    "id": "_JscbREmdHC-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:48:13.141309Z",
     "start_time": "2020-01-29T10:48:13.137453Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "# FIX: Use the official public API path from pandas.errors\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "# feel free to modify, for example, change the context to \"notebook\"\n",
    "sns.set_theme(context=\"talk\", style=\"whitegrid\", \n",
    "              palette=\"colorblind\", color_codes=True, \n",
    "              rc={\"figure.figsize\": [12, 8]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nS3hr1kUdHDB"
   },
   "source": [
    "# Chapter 4 - Exploring Financial Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg_qiT70dHDC"
   },
   "source": [
    "## 4.1 Outlier detection using rolling statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fxt7NSaSdHDC"
   },
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T08:23:57.156436Z",
     "start_time": "2020-01-24T08:23:56.272058Z"
    },
    "id": "ZjjPcO62dHDC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D7Bsp6gdHDD"
   },
   "source": [
    "2. Download Tesla's stock prices from 2019-2020 and calculate simple returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T08:23:57.729742Z",
     "start_time": "2020-01-24T08:23:57.176457Z"
    },
    "id": "lYcMxZ9KdHDD",
    "outputId": "44161c51-f79f-4f8d-fa9c-d92c02873a34"
   },
   "outputs": [],
   "source": [
    "df = yf.download(\"TSLA\", \n",
    "                 start=\"2019-01-01\", \n",
    "                 end=\"2020-12-31\",\n",
    "                 progress=False)\n",
    "\n",
    "# FIX: Use the 'Close' column, which now contains the adjusted close price\n",
    "df[\"rtn\"] = df[\"Close\"].pct_change()\n",
    "df = df[[\"rtn\"]].copy()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YL-eyWndHDF"
   },
   "source": [
    "3. Calculate the rolling mean and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T08:23:59.808044Z",
     "start_time": "2020-01-24T08:23:59.794563Z"
    },
    "id": "06EdO-8qdHDF",
    "outputId": "d49a4b93-3f32-4ddc-ce6b-fde3715295ee"
   },
   "outputs": [],
   "source": [
    "df_rolling = df[[\"rtn\"]].rolling(window=21) \\\n",
    "                        .agg([\"mean\", \"std\"])\n",
    "df_rolling.columns = df_rolling.columns.droplevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Join the rolling data back to the initial DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df_rolling)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sP5kPf1ddHDF"
   },
   "source": [
    "5. Calculate the upper and lower thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2i5kHv8FdHDG"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Step 1: Download the data\n",
    "df = yf.download(\"TSLA\", \n",
    "                 start=\"2019-01-01\", \n",
    "                 end=\"2020-12-31\",\n",
    "                 progress=False,\n",
    "                 auto_adjust=True)\n",
    "\n",
    "# Step 2: FIX - Calculate the returns and create the 'rtn' column first\n",
    "df[\"rtn\"] = df[\"Close\"].pct_change()\n",
    "\n",
    "# Step 3: FIX - Now calculate the rolling mean and std from the 'rtn' column\n",
    "df['mean'] = df['rtn'].rolling(window=30).mean()\n",
    "df['std'] = df['rtn'].rolling(window=30).std()\n",
    "\n",
    "# Step 4: The original code for the bands will now work\n",
    "N_SIGMAS = 3\n",
    "df[\"upper\"] = df[\"mean\"] + N_SIGMAS * df[\"std\"]\n",
    "df[\"lower\"] = df[\"mean\"] - N_SIGMAS * df[\"std\"]\n",
    "\n",
    "# Display the first few rows of the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRqqWfUQdHDG"
   },
   "source": [
    "6. Identify the outliers using the previously calculated thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoucJZlkdHDH"
   },
   "outputs": [],
   "source": [
    "df[\"outlier\"] = (\n",
    "    (df[\"rtn\"] > df[\"upper\"]) | (df[\"rtn\"] < df[\"lower\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OomwUiGndHDH"
   },
   "source": [
    "7. Plot the returns together with the thresholds and mark the outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jG9CWYCdHDH",
    "outputId": "c5c667ec-4d8f-404a-b25d-5b7be2029fb8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "df[[\"rtn\", \"upper\", \"lower\"]].plot(ax=ax)\n",
    "ax.scatter(df.loc[df[\"outlier\"]].index, \n",
    "           df.loc[df[\"outlier\"], \"rtn\"], \n",
    "           color=\"black\", label=\"outlier\")\n",
    "ax.set_title(\"Tesla's stock returns\")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_4_1\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for identify outliers using the steps described in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers(df, column, window_size, n_sigmas):\n",
    "    \"\"\"Function for identifying outliers using rolling statistics\"\"\"\n",
    "    \n",
    "    # Make a copy to avoid modifying the original DataFrame\n",
    "    df_copy = df[[column]].copy()\n",
    "    \n",
    "    # FIX: Calculate rolling stats and assign them directly as new columns\n",
    "    df_copy[\"mean\"] = df_copy[column].rolling(window=window_size).mean()\n",
    "    df_copy[\"std\"] = df_copy[column].rolling(window=window_size).std()\n",
    "    \n",
    "    # FIX: Calculate upper and lower bands on this new DataFrame\n",
    "    df_copy[\"upper\"] = df_copy[\"mean\"] + n_sigmas * df_copy[\"std\"]\n",
    "    df_copy[\"lower\"] = df_copy[\"mean\"] - n_sigmas * df_copy[\"std\"]\n",
    "    \n",
    "    # Return the boolean series indicating outliers\n",
    "    return (df_copy[column] > df_copy[\"upper\"]) | (df_copy[column] < df_copy[\"lower\"])\n",
    "\n",
    "# The function call remains the same\n",
    "identify_outliers(df, \"rtn\", 21, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Outlier detection with the Hampel filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: Install the sktime library\n",
    "!pip install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPfBrHKveOxU"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from sktime.transformations.series.outlier_detection import HampelFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download Tesla's stock prices from 2019-2020 and calculate simple returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrDBbwsUeM3x"
   },
   "outputs": [],
   "source": [
    "df = yf.download(\"TSLA\", \n",
    "                 start=\"2019-01-01\", \n",
    "                 end=\"2020-12-31\",\n",
    "                 progress=False)\n",
    "df[\"rtn\"] = df[\"Adj Close\"].pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Instantiate the `HampelFilter` class and use it for detecting the outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "EXwThb58eYeS",
    "outputId": "3033e2af-689e-4308-8c24-3b101f982e6f"
   },
   "outputs": [],
   "source": [
    "hampel_detector = HampelFilter(window_length=10, \n",
    "                               return_bool=True)\n",
    "df[\"outlier\"] = hampel_detector.fit_transform(df[\"Adj Close\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Plot Tesla's stock price and mark the outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IpC6-jf7eSvt",
    "outputId": "af7ac0e2-3eee-4cb8-88e3-25254505af21"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "df[[\"Adj Close\"]].plot(ax=ax)\n",
    "ax.scatter(df.loc[df[\"outlier\"]].index, \n",
    "           df.loc[df[\"outlier\"], \"Adj Close\"], \n",
    "           color=\"black\", label=\"outlier\")\n",
    "ax.set_title(\"Tesla's stock price\")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_4_2\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identify the outliers among the stock returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "aiYUJirZ-S4Z",
    "outputId": "cc369034-667d-445e-dc82-ddd5699cd042"
   },
   "outputs": [],
   "source": [
    "df[\"outlier_rtn\"] = hampel_detector.fit_transform(df[\"rtn\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Plot Tesla's daily returns and mark the outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gg7Wo6w_-TBy",
    "outputId": "eb418a40-9c4f-453c-b62e-f9b1c911a6c8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "df[[\"rtn\"]].plot(ax=ax)\n",
    "ax.scatter(df.loc[df[\"outlier_rtn\"]].index, \n",
    "           df.loc[df[\"outlier_rtn\"], \"rtn\"], \n",
    "           color=\"black\", label=\"outlier\")\n",
    "ax.set_title(\"Tesla's stock returns\")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_4_3\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Investigate the overlap in outliers identified for the prices and returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "6bF3cKcE-TF9",
    "outputId": "18ee2e17-a11a-4079-9c34-be50b03e5898"
   },
   "outputs": [],
   "source": [
    "df.query(\"outlier == True and outlier_rtn == True\").round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Detecting changepoints in time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from kats.detectors.cusum_detection import CUSUMDetector\n",
    "from kats.consts import TimeSeriesData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download Apple's stock price from 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yf.download(\"AAPL\", \n",
    "                 start=\"2020-01-01\", \n",
    "                 end=\"2020-12-31\", \n",
    "                 progress=False)\n",
    "df[\"Adj Close\"].plot(title=\"Apple's stock in 2020\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Keep only the adjusted close price, reset the index and rename the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Adj Close\"]].reset_index(drop=False)\n",
    "df.columns = [\"time\", \"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Convert the DataFrame into a `TimeSeriesData` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd = TimeSeriesData(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Instantiate and run the changepoint detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cusum_detector = CUSUMDetector(tsd)\n",
    "change_points = cusum_detector.detector(\n",
    "    change_directions=[\"increase\"]\n",
    ")\n",
    "cusum_detector.plot(change_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Investigate the detected changepoint in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point, meta = change_points[0]\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Narrow down the window in which we want to search for the changepoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_points = cusum_detector.detector(change_directions=[\"increase\"], \n",
    "                                        interest_window=[200, 250])\n",
    "cusum_detector.plot(change_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use another algorithm to detect changepoints (`RobustStatDetector`): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.detectors.robust_stat_detection import RobustStatDetector\n",
    "\n",
    "robust_detector = RobustStatDetector(tsd)\n",
    "change_points = robust_detector.detector()\n",
    "robust_detector.plot(change_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Change the `RobustStatDetector`'s default arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_detector = RobustStatDetector(tsd)\n",
    "changepoints = robust_detector.detector(p_value_cutoff = 0.01, comparison_window=-5)\n",
    "robust_detector.plot(changepoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.4 Detecting trends in time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from kats.consts import TimeSeriesData\n",
    "from kats.detectors.trend_mk import MKDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download NVIDIA's stock prices from 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yf.download(\"NVDA\", \n",
    "                 start=\"2020-01-01\", \n",
    "                 end=\"2020-12-31\", \n",
    "                 progress=False)\n",
    "df[\"Adj Close\"].plot(title=\"NVIDIA's stock in 2020\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Keep only the adjusted close price, reset the index and rename the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Adj Close\"]].reset_index(drop=False)\n",
    "df.columns = [\"time\", \"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Convert the DataFrame into a `TimeSeriesData` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd = TimeSeriesData(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Instantiate and run the trend detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_detector = MKDetector(tsd, threshold=0.9)\n",
    "time_points = trend_detector.detector(\n",
    "    direction=\"up\", \n",
    "    window_size=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Plot the detected time points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_detector.plot(time_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Investigate the detected points in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect a single time point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp, meta = time_points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Detecting patterns in a time series using the Hurst exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download S&P 500's historical prices from the years 2000-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yf.download(\"^GSPC\", \n",
    "                 start=\"2000-01-01\", \n",
    "                 end=\"2019-12-31\", \n",
    "                 progress=False)\n",
    "df[\"Adj Close\"].plot(title=\"S&P 500 (years 2000-2019)\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_4_9\", dpi=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a function calculating the Hurst exponent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hurst_exponent(ts, max_lag=20):\n",
    "    \"\"\"Returns the Hurst Exponent of the time series\"\"\"\n",
    "    \n",
    "    lags = range(2, max_lag)\n",
    "\n",
    "    # standard deviations of the lagged differences\n",
    "    tau = [np.std(np.subtract(ts[lag:], ts[:-lag])) for lag in lags]\n",
    "\n",
    "    # calculate the slope of the log plot -> the Hurst Exponent\n",
    "    hurst_exp = np.polyfit(np.log(lags), np.log(tau), 1)[0]\n",
    "\n",
    "    return hurst_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calculate the values of the Hurst exponent using different values for the `max_lag` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in [20, 100, 250, 500, 1000]:\n",
    "    hurst_exp = get_hurst_exponent(df[\"Adj Close\"].values, lag)\n",
    "    print(f\"Hurst exponent with {lag} lags: {hurst_exp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Narrow down the data to the years 2005-2007 and calculate the exponents one more time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"2005\":\"2007\", \"Adj Close\"].plot(title=\"S&P 500 (years 2005-2007)\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_4_10\", dpi=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorter_series = df.loc[\"2005\":\"2007\", \"Adj Close\"].values\n",
    "for lag in [20, 100, 250, 500]:\n",
    "    hurst_exp = get_hurst_exponent(shorter_series, lag)\n",
    "    print(f\"Hurst exponent with {lag} lags: {hurst_exp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywdJEJSPdHDI"
   },
   "source": [
    "## 4.6 Investigating stylized facts of asset returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brqZvaX7dHDK"
   },
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7gd-t9pdHDK"
   },
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T09:20:49.524092Z",
     "start_time": "2020-01-24T09:20:48.247943Z"
    },
    "id": "stQPShzZdHDK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import seaborn as sns \n",
    "import scipy.stats as scs\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qgjtw70dHDK"
   },
   "source": [
    "2. Download the S&P 500 data and calculate the returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T09:20:50.912418Z",
     "start_time": "2020-01-24T09:20:49.645295Z"
    },
    "id": "VrdXXXAFdHDK"
   },
   "outputs": [],
   "source": [
    "df = yf.download(\"^GSPC\", \n",
    "                 start=\"2000-01-01\", \n",
    "                 end=\"2020-12-31\",\n",
    "                 progress=False)\n",
    "\n",
    "df = df[[\"Adj Close\"]].rename(\n",
    "    columns={\"Adj Close\": \"adj_close\"}\n",
    ")\n",
    "df[\"log_rtn\"] = np.log(df[\"adj_close\"]/df[\"adj_close\"].shift(1))\n",
    "df = df[[\"adj_close\", \"log_rtn\"]].dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlsYzu0tdHDK"
   },
   "source": [
    "#### Fact 1 - Non-Gaussian distribution of returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFiPdnuNdHDK"
   },
   "source": [
    "1. Calculate the Normal PDF using the mean and standard deviation of the observed returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T20:42:40.413622Z",
     "start_time": "2020-01-18T20:42:40.406694Z"
    },
    "id": "qzzeheNndHDK"
   },
   "outputs": [],
   "source": [
    "r_range = np.linspace(min(df[\"log_rtn\"]), \n",
    "                      max(df[\"log_rtn\"]), \n",
    "                      num=1000)\n",
    "mu = df[\"log_rtn\"].mean()\n",
    "sigma = df[\"log_rtn\"].std()\n",
    "norm_pdf = scs.norm.pdf(r_range, loc=mu, scale=sigma)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNbd1rT4dHDK"
   },
   "source": [
    "2. Plot the histogram and the Q-Q Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T20:42:48.622292Z",
     "start_time": "2020-01-18T20:42:43.620604Z"
    },
    "id": "z0x_AWuqdHDK"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# histogram\n",
    "sns.distplot(df.log_rtn, kde=False, \n",
    "             norm_hist=True, ax=ax[0])                                    \n",
    "ax[0].set_title(\"Distribution of S&P 500 returns\", \n",
    "                fontsize=16)                                                    \n",
    "ax[0].plot(r_range, norm_pdf, \"g\", lw=2, \n",
    "           label=f\"N({mu:.2f}, {sigma**2:.4f})\")\n",
    "ax[0].legend(loc=\"upper left\");\n",
    "\n",
    "# Q-Q plot\n",
    "qq = sm.qqplot(df.log_rtn.values, line=\"s\", ax=ax[1])\n",
    "ax[1].set_title(\"Q-Q plot\", fontsize = 16)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_4_11\", dpi=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGqNYv_4dHDL"
   },
   "source": [
    "3. Print the summary statistics of the log returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:19:40.593707Z",
     "start_time": "2019-11-25T18:19:40.576949Z"
    },
    "id": "xXaviOGHdHDL"
   },
   "outputs": [],
   "source": [
    "jb_test = scs.jarque_bera(df[\"log_rtn\"].values)\n",
    "\n",
    "print(\"---------- Descriptive Statistics ----------\")\n",
    "print(\"Range of dates:\", min(df.index.date), \"-\", max(df.index.date))\n",
    "print(\"Number of observations:\", df.shape[0])\n",
    "print(f\"Mean: {df.log_rtn.mean():.4f}\")\n",
    "print(f\"Median: {df.log_rtn.median():.4f}\")\n",
    "print(f\"Min: {df.log_rtn.min():.4f}\")\n",
    "print(f\"Max: {df.log_rtn.max():.4f}\")\n",
    "print(f\"Standard Deviation: {df.log_rtn.std():.4f}\")\n",
    "print(f\"Skewness: {df.log_rtn.skew():.4f}\")\n",
    "print(f\"Kurtosis: {df.log_rtn.kurtosis():.4f}\") \n",
    "print(f\"Jarque-Bera statistic: {jb_test[0]:.2f} with p-value: {jb_test[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uG3_7uqdHDL"
   },
   "source": [
    "#### Fact 2 - Volatility Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtnoIabkdHDM"
   },
   "source": [
    "1. Run the following code to visualize the log returns series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T20:44:11.932467Z",
     "start_time": "2020-01-18T20:44:09.068369Z"
    },
    "id": "LXabAKvQdHDM"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df[\"log_rtn\"]\n",
    "    .plot(title=\"Daily S&P 500 returns\", figsize=(10, 6))\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_4_12\", dpi=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elXwX_QzdHDM"
   },
   "source": [
    "#### Fact 3 - Absence of autocorrelation in returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ShyCKfGdHDM"
   },
   "source": [
    "1. Define the parameters for creating the autocorrelation plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T09:20:58.768842Z",
     "start_time": "2020-01-24T09:20:58.766192Z"
    },
    "id": "6WatQSJXdHDM"
   },
   "outputs": [],
   "source": [
    "N_LAGS = 50\n",
    "SIGNIFICANCE_LEVEL = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVps6UpndHDN"
   },
   "source": [
    "2. Run the following code to create ACF plot of log returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T20:44:20.601220Z",
     "start_time": "2020-01-18T20:44:18.830993Z"
    },
    "id": "waUjyynYdHDN"
   },
   "outputs": [],
   "source": [
    "acf = smt.graphics.plot_acf(df[\"log_rtn\"], \n",
    "                            lags=N_LAGS, \n",
    "                            alpha=SIGNIFICANCE_LEVEL)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_4_13\", dpi=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAQofX23dHDN"
   },
   "source": [
    "#### Fact 4 - Small and decreasing autocorrelation in squared/absolute returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the ACF plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T09:21:12.668244Z",
     "start_time": "2020-01-24T09:21:09.467196Z"
    },
    "id": "IUBsvmYSdHDN"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "smt.graphics.plot_acf(df[\"log_rtn\"]**2, lags=N_LAGS, \n",
    "                      alpha=SIGNIFICANCE_LEVEL, ax=ax[0])\n",
    "ax[0].set(title=\"Autocorrelation Plots\",\n",
    "          ylabel=\"Squared Returns\")\n",
    "\n",
    "smt.graphics.plot_acf(np.abs(df[\"log_rtn\"]), lags=N_LAGS, \n",
    "                      alpha=SIGNIFICANCE_LEVEL, ax=ax[1])\n",
    "ax[1].set(ylabel=\"Absolute Returns\",\n",
    "          xlabel=\"Lag\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_4_14\", dpi=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GF1y4U-adHDN"
   },
   "source": [
    "#### Fact 5 - Leverage effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxJNqU6qdHDO"
   },
   "source": [
    "1. Calculate volatility measures as moving standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T20:44:26.961992Z",
     "start_time": "2020-01-18T20:44:26.951096Z"
    },
    "id": "jskPQE9FdHDO"
   },
   "outputs": [],
   "source": [
    "df[\"rolling_std_252\"] = df[[\"log_rtn\"]].rolling(window=252).std()\n",
    "df[\"rolling_std_21\"] = df[[\"log_rtn\"]].rolling(window=21).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T20:11:34.163948Z",
     "start_time": "2019-04-17T20:11:32.792676Z"
    },
    "id": "j8eY-7z5dHDO"
   },
   "source": [
    "2. Plot all the series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T20:45:33.295664Z",
     "start_time": "2020-01-18T20:45:22.079437Z"
    },
    "id": "ffQhZVgwdHDO"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(18, 15), \n",
    "                       sharex=True)\n",
    "\n",
    "df[\"adj_close\"].plot(ax=ax[0])\n",
    "ax[0].set(title=\"S&P 500 time series\",\n",
    "          ylabel=\"Price ($)\")\n",
    "\n",
    "df[\"log_rtn\"].plot(ax=ax[1])\n",
    "ax[1].set(ylabel=\"Log returns\")\n",
    "\n",
    "df[\"rolling_std_252\"].plot(ax=ax[2], color=\"r\", \n",
    "                           label=\"Rolling Volatility 252d\")\n",
    "df[\"rolling_std_21\"].plot(ax=ax[2], color=\"g\", \n",
    "                           label=\"Rolling Volatility 21d\")\n",
    "ax[2].set(ylabel=\"Moving Volatility\",\n",
    "          xlabel=\"Date\")\n",
    "ax[2].legend()\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_4_15\", dpi=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-pUxl8WdHDO"
   },
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7iLcJWZdHDO"
   },
   "source": [
    "1. Download and preprocess the prices of the S&P 500 and VIX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T20:47:21.656138Z",
     "start_time": "2020-01-18T20:47:21.173226Z"
    },
    "id": "_06tywMUdHDO"
   },
   "outputs": [],
   "source": [
    "df = yf.download([\"^GSPC\", \"^VIX\"], \n",
    "                 start=\"2000-01-01\", \n",
    "                 end=\"2020-12-31\",\n",
    "                 progress=False)\n",
    "df = df[[\"Adj Close\"]]\n",
    "df.columns = df.columns.droplevel(0)\n",
    "df = df.rename(columns={\"^GSPC\": \"sp500\", \"^VIX\": \"vix\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaDj2fzFdHDP"
   },
   "source": [
    "2. Calculate the log returns (we can just as well use percentage change-simple returns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T20:47:22.250306Z",
     "start_time": "2020-01-18T20:47:22.241051Z"
    },
    "id": "HZ_Yr7q-dHDP"
   },
   "outputs": [],
   "source": [
    "df[\"log_rtn\"] = np.log(df[\"sp500\"] / df[\"sp500\"].shift(1))\n",
    "df[\"vol_rtn\"] = np.log(df[\"vix\"] / df[\"vix\"].shift(1))\n",
    "df.dropna(how=\"any\", axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygThbTumdHDP"
   },
   "source": [
    "3. Plot a scatterplot with the returns on the axes and fit a regression line to identify the trend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T20:47:26.416650Z",
     "start_time": "2020-01-18T20:47:23.506994Z"
    },
    "id": "FZf2m2JDdHDP",
    "outputId": "635a24d1-9c9d-49a2-c78e-2e146bb8b7ae"
   },
   "outputs": [],
   "source": [
    "corr_coeff = df.log_rtn.corr(df.vol_rtn)\n",
    "\n",
    "ax = sns.regplot(x=\"log_rtn\", y=\"vol_rtn\", data=df, \n",
    "                 line_kws={\"color\": \"red\"})\n",
    "ax.set(title=f\"S&P 500 vs. VIX ($\\\\rho$ = {corr_coeff:.2f})\",\n",
    "       ylabel=\"VIX log returns\",\n",
    "       xlabel=\"S&P 500 log returns\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_4_16\", dpi=200);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter_4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "0117835dafdb051235b33d006a7ad155411608685e1d44af6fb551f6db3e7774"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
