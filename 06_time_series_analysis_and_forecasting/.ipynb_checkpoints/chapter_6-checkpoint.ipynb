{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OEACZptdHC7"
   },
   "source": [
    "Please run those two cells before running the Notebook!\n",
    "\n",
    "As those plotting settings are standard throughout the book, we do not show them in the book every time we plot something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: seaborn in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.3.1-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.0 MB 4.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.8/11.0 MB 4.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.6/11.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.4/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.2/11.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 4.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.6/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.10.3-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/8.1 MB 4.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.8/8.1 MB 4.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.9/8.1 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.4/8.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 4.5/8.1 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.5/8.1 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.6/8.1 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.6/8.1 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pandas, matplotlib\n",
      "\n",
      "  Attempting uninstall: pandas\n",
      "\n",
      "    Found existing installation: pandas 2.2.3\n",
      "\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "    Uninstalling pandas-2.2.3:\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "  Attempting uninstall: matplotlib\n",
      "   ---------------------------------------- 0/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "    Found existing installation: matplotlib 3.10.0\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "    Uninstalling matplotlib-3.10.0:\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "      Successfully uninstalled matplotlib-3.10.0\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   -------------------- ------------------- 1/2 [matplotlib]\n",
      "   ---------------------------------------- 2/2 [matplotlib]\n",
      "\n",
      "Successfully installed matplotlib-3.10.3 pandas-2.3.1\n"
     ]
    }
   ],
   "source": [
    "# FIX: Update the core libraries to resolve version conflicts\n",
    "!pip install --upgrade pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:48:06.120195Z",
     "start_time": "2020-01-29T10:48:05.814125Z"
    },
    "id": "_JscbREmdHC-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:48:13.141309Z",
     "start_time": "2020-01-29T10:48:13.137453Z"
    },
    "id": "r6OEEsWTdHDB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "# FIX: Use the official public API path from pandas.errors\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "# feel free to modify, for example, change the context to \"notebook\"\n",
    "sns.set_theme(context=\"talk\", style=\"whitegrid\", \n",
    "              palette=\"colorblind\", color_codes=True, \n",
    "              rc={\"figure.figsize\": [12, 8]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Time Series Analysis and Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Time series decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mlxtend) (1.15.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mlxtend) (2.2.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mlxtend) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mlxtend) (1.6.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mlxtend) (3.10.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "# FIX: Install the mlxtend library for association rule mining\n",
    "!pip install mlxtend\n",
    "\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import yfinance as yf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FIX: You must import the library before you can use it\n",
    "import nasdaqdatalink\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YK5hwjxe3Swf2y_zTjxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the monthly US unemployment rate from years 2010-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-datareader in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas-datareader) (5.3.0)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas-datareader) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas-datareader) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.23->pandas-datareader) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2025.7.14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unemp_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-01</th>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01</th>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-01</th>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-01</th>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            unemp_rate\n",
       "DATE                  \n",
       "2010-01-01        10.6\n",
       "2010-02-01        10.4\n",
       "2010-03-01        10.2\n",
       "2010-04-01         9.5\n",
       "2010-05-01         9.3"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIX: Install the pandas-datareader library to connect directly to the FRED database\n",
    "!pip install pandas-datareader\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "import pandas as pd\n",
    "\n",
    "# FIX: Download the data directly from FRED using its series ID \"UNRATENSA\"\n",
    "df = (\n",
    "    web.DataReader(name=\"UNRATENSA\", \n",
    "                   data_source=\"fred\",\n",
    "                   start=\"2010-01-01\",\n",
    "                   end=\"2019-12-31\")\n",
    "    .rename(columns={\"UNRATENSA\": \"unemp_rate\"})\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Download the data for multiple tickers\n",
    "df = yf.download(['AAPL', 'MSFT', 'AMZN', 'GOOG', 'TSLA', \n",
    "                  'BRK-B', 'JPM', 'JNJ', 'V', 'PG'],\n",
    "                 start=\"2019-01-01\",\n",
    "                 end=\"2020-12-31\",\n",
    "                 progress=False,\n",
    "                 auto_adjust=True)\n",
    "\n",
    "# calculate daily returns\n",
    "# FIX: Use the 'Close' column which now contains the adjusted close price\n",
    "df_rtn = df['Close'].pct_change()\n",
    "\n",
    "# Discretize the returns into \"up\" and \"down\" days\n",
    "df_discretized = df_rtn.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Apply the Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(df_discretized, \n",
    "                            min_support=0.25, \n",
    "                            use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, \n",
    "                          metric=\"lift\", \n",
    "                          min_threshold=1)\n",
    "\n",
    "# Display the rules\n",
    "print(rules.head())\n",
    "\n",
    "# The following is the plotting code from the original notebook,\n",
    "# now placed here to run with the corrected data.\n",
    "# a quick look at the plot\n",
    "temp_df = df_rtn.copy() # Using df_rtn for the plot as intended by the original notebook\n",
    "\n",
    "temp_df[\"year\"] = temp_df.index.year\n",
    "temp_df[\"month\"] = temp_df.index.strftime(\"%b\")\n",
    "\n",
    "# FIX: Convert the 'month' column to a categorical type with a defined order\n",
    "month_order = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \n",
    "               \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "temp_df['month'] = pd.Categorical(temp_df['month'], categories=month_order, ordered=True)\n",
    "\n",
    "# Now, your plotting code will work correctly\n",
    "# Note: You may need to select a single stock's returns for a meaningful plot\n",
    "# Here, we'll plot Apple's (AAPL) returns as an example.\n",
    "sns.lineplot(data=temp_df, \n",
    "             x=\"month\", \n",
    "             y=\"AAPL\",  # Changed from \"unemp_rate\" to a valid column like \"AAPL\"\n",
    "             hue=\"year\",\n",
    "             style=\"year\", \n",
    "             legend=\"full\",\n",
    "             palette=\"colorblind\")\n",
    "\n",
    "plt.title(\"AAPL Stock Returns - Seasonal plot\") # Updated title\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2);\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Add rolling mean and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:46:01.544502Z",
     "start_time": "2020-01-24T21:45:59.878611Z"
    }
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 12\n",
    "df[\"rolling_mean\"] = df[\"unemp_rate\"].rolling(window=WINDOW_SIZE).mean()\n",
    "df[\"rolling_std\"] = df[\"unemp_rate\"].rolling(window=WINDOW_SIZE).std()\n",
    "df.plot(title=\"Unemployment rate\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_3\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Carry out seasonal decomposition using the additive model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:46:23.211727Z",
     "start_time": "2020-01-24T21:46:20.429946Z"
    }
   },
   "outputs": [],
   "source": [
    "# FIX: Import the seasonal_decompose function from statsmodels\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "decomposition_results = seasonal_decompose(df[\"unemp_rate\"], \n",
    "                                           model=\"additive\")\n",
    "(\n",
    "    decomposition_results\n",
    "    .plot()\n",
    "    .suptitle(\"Additive Decomposition\")\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_4\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the STL decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "stl_decomposition = STL(df[[\"unemp_rate\"]]).fit()\n",
    "stl_decomposition.plot() \\\n",
    "                 .suptitle(\"STL Decomposition\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_5\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the decompositions with and without the robust setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_second_stl_to_plot(fig, fitted_stl, labels):\n",
    "    \"\"\"\n",
    "    A helper function adding the 3 components from the second STL fit to the \n",
    "    first STL plot\n",
    "    \"\"\"\n",
    "    axs = fig.get_axes()\n",
    "    comps = [\"trend\", \"seasonal\", \"resid\"]\n",
    "    for ax, comp in zip(axs[1:], comps):\n",
    "        series = getattr(fitted_stl, comp)\n",
    "        if comp == \"resid\":\n",
    "            ax.plot(series, marker=\"o\", linestyle=\"none\")\n",
    "        else:\n",
    "            ax.plot(series)\n",
    "            if comp == \"trend\":\n",
    "                ax.legend(labels, frameon=False)\n",
    "\n",
    "\n",
    "stl_robust = STL(df[[\"unemp_rate\"]], robust=True).fit()\n",
    "stl_non_robust = STL(df[[\"unemp_rate\"]], robust=False).fit()\n",
    "fig = stl_robust.plot()\n",
    "add_second_stl_to_plot(fig, stl_non_robust, [\"Robust\", \"Non-robust\"])\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_6\", dpi=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Hodrick-Prescott filter to the unemployment time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "\n",
    "hp_df = df[[\"unemp_rate\"]].copy()\n",
    "hp_df[\"cycle\"], hp_df[\"trend\"] = hpfilter(hp_df[\"unemp_rate\"], 129600)\n",
    "hp_df.plot(subplots=True, title=\"Hodrick-Prescott filter\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Testing for stationarity in time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nasdaqdatalink\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the monthly US unemployment rate from years 2010-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    nasdaqdatalink.get(dataset=\"FRED/UNRATENSA\", \n",
    "                       start_date=\"2010-01-01\", \n",
    "                       end_date=\"2019-12-31\")\n",
    "    .rename(columns={\"Value\": \"unemp_rate\"})\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:49:15.359395Z",
     "start_time": "2020-01-24T21:49:15.286297Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller, kpss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a function for running the ADF test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:49:15.548821Z",
     "start_time": "2020-01-24T21:49:15.543963Z"
    }
   },
   "outputs": [],
   "source": [
    "def adf_test(x):\n",
    "    \"\"\"\n",
    "    Function for performing the Augmented Dickey-Fuller test for stationarity\n",
    "    \n",
    "    Null Hypothesis: time series is not stationary\n",
    "    Alternate Hypothesis: time series is stationary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : pd.Series / np.array\n",
    "        The time series to be checked for stationarity\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results: pd.DataFrame\n",
    "        A DataFrame with the ADF test's results\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = [\"Test Statistic\", \"p-value\",\n",
    "               \"# of Lags Used\", \"# of Observations Used\"]\n",
    "    \n",
    "    adf_test = adfuller(x, autolag=\"AIC\")\n",
    "    results = pd.Series(adf_test[0:4], index=indices)\n",
    "    \n",
    "    for key, value in adf_test[4].items():\n",
    "        results[f\"Critical Value ({key})\"] = value\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:49:16.012301Z",
     "start_time": "2020-01-24T21:49:15.995862Z"
    }
   },
   "outputs": [],
   "source": [
    "adf_test(df[\"unemp_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a function for running the KPSS test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:49:16.885175Z",
     "start_time": "2020-01-24T21:49:16.881035Z"
    }
   },
   "outputs": [],
   "source": [
    "def kpss_test(x, h0_type=\"c\"):\n",
    "    \"\"\"\n",
    "    Function for performing the Kwiatkowski-Phillips-Schmidt-Shin test for stationarity\n",
    "\n",
    "    Null Hypothesis: time series is stationary\n",
    "    Alternate Hypothesis: time series is not stationary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: pd.Series / np.array\n",
    "        The time series to be checked for stationarity\n",
    "    h0_type: str{\"c\", \"ct\"}\n",
    "        Indicates the null hypothesis of the KPSS test:\n",
    "            * \"c\": The data is stationary around a constant(default)\n",
    "            * \"ct\": The data is stationary around a trend\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results: pd.DataFrame\n",
    "        A DataFrame with the KPSS test's results\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = [\"Test Statistic\", \"p-value\", \"# of Lags\"]\n",
    "\n",
    "    kpss_test = kpss(x, regression=h0_type)\n",
    "    results = pd.Series(kpss_test[0:3], index=indices)\n",
    "    \n",
    "    for key, value in kpss_test[3].items():\n",
    "        results[f\"Critical Value ({key})\"] = value\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:49:17.354674Z",
     "start_time": "2020-01-24T21:49:17.343459Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kpss_test(df[\"unemp_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Generate the ACF/PACF plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:49:24.762596Z",
     "start_time": "2020-01-24T21:49:22.852022Z"
    }
   },
   "outputs": [],
   "source": [
    "N_LAGS = 40\n",
    "SIGNIFICANCE_LEVEL = 0.05\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "plot_acf(df[\"unemp_rate\"], ax=ax[0], lags=N_LAGS, \n",
    "         alpha=SIGNIFICANCE_LEVEL)\n",
    "plot_pacf(df[\"unemp_rate\"], ax=ax[1], lags=N_LAGS, \n",
    "          alpha=SIGNIFICANCE_LEVEL)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_7\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carry out the ADF test using the `arch` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch.unitroot import ADF\n",
    "adf = ADF(df[\"unemp_rate\"])\n",
    "print(adf.summary().as_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Carry out the Zivot-Andrews test using the `arch` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch.unitroot import ZivotAndrews\n",
    "za = ZivotAndrews(df[\"unemp_rate\"])\n",
    "print(za.summary().as_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Correcting for stationarity in time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries, authenticate and update the inflation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:53:10.615420Z",
     "start_time": "2020-01-24T21:52:48.302981Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nasdaqdatalink\n",
    "import cpi\n",
    "from datetime import date\n",
    "from chapter_6_utils import test_autocorrelation\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YOUR_KEY_HERE\"\n",
    "\n",
    "# update the CPI data (if needed)\n",
    "# cpi.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the prices of gold for 2000-2010 and resample to monthly values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    nasdaqdatalink.get(dataset=\"WGC/GOLD_MONAVG_USD\", \n",
    "                       start_date=\"2000-01-01\", \n",
    "                       end_date=\"2010-12-31\")\n",
    "    .rename(columns={\"Value\": \"price\"})\n",
    "    .resample(\"M\")\n",
    "    .last()\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a confirmation, we can check if the series is stationary -> it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = test_autocorrelation(df[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Deflate the gold prices (to 2010-12-31 USD values) and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:53:15.208464Z",
     "start_time": "2020-01-24T21:53:13.250692Z"
    }
   },
   "outputs": [],
   "source": [
    "DEFL_DATE = date(2010, 12, 31)\n",
    "\n",
    "df[\"dt_index\"] = pd.to_datetime(df.index)\n",
    "df[\"price_deflated\"] = df.apply(\n",
    "    lambda x: cpi.inflate(x[\"price\"], x[\"dt_index\"], DEFL_DATE), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "(\n",
    "    df.loc[:, [\"price\", \"price_deflated\"]]\n",
    "    .plot(title=\"Gold Price (deflated)\")\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_8\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Apply the natural logarithm to the deflated series and plot it together with the rolling metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:53:36.171230Z",
     "start_time": "2020-01-24T21:53:34.203259Z"
    }
   },
   "outputs": [],
   "source": [
    "WINDOW = 12\n",
    "selected_columns = [\"price_log\", \"rolling_mean_log\", \n",
    "                    \"rolling_std_log\"]\n",
    "\n",
    "df[\"price_log\"] = np.log(df.price_deflated)\n",
    "df[\"rolling_mean_log\"] = df.price_log.rolling(WINDOW) \\\n",
    "                           .mean()\n",
    "df[\"rolling_std_log\"] = df.price_log.rolling(WINDOW) \\\n",
    "                          .std()\n",
    "\n",
    "(\n",
    "    df[selected_columns]\n",
    "    .plot(title=\"Gold Price (deflated + logged)\", \n",
    "          subplots=True)\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_9\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use the `test_autocorrelation` (helper function for this chapter) to investigate if the series became stationary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:53:47.204327Z",
     "start_time": "2020-01-24T21:53:41.231437Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = test_autocorrelation(df[\"price_log\"])\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_10\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Apply differencing to the series and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:54:08.490780Z",
     "start_time": "2020-01-24T21:54:06.362378Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_columns = [\"price_log_diff\", \"roll_mean_log_diff\", \n",
    "                    \"roll_std_log_diff\"]\n",
    "\n",
    "df[\"price_log_diff\"] = df.price_log.diff(1)\n",
    "df[\"roll_mean_log_diff\"] = df.price_log_diff.rolling(WINDOW) \\\n",
    "                             .mean()\n",
    "df[\"roll_std_log_diff\"] = df.price_log_diff.rolling(WINDOW) \\\n",
    "                            .std()\n",
    "df[selected_columns].plot(title=\"Gold Price (deflated + log + diff)\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_11\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Test if the series became stationary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:54:18.027058Z",
     "start_time": "2020-01-24T21:54:12.489536Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = test_autocorrelation(df[\"price_log_diff\"].dropna())\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_12\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:04:33.356900Z",
     "start_time": "2020-01-24T22:04:32.849648Z"
    }
   },
   "outputs": [],
   "source": [
    "from pmdarima.arima import ndiffs, nsdiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:04:43.984339Z",
     "start_time": "2020-01-24T22:04:43.959729Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Suggested # of differences (ADF): {ndiffs(df['price'], test='adf')}\")\n",
    "print(f\"Suggested # of differences (KPSS): {ndiffs(df['price'], test='kpss')}\")\n",
    "print(f\"Suggested # of differences (PP): {ndiffs(df['price'], test='pp')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:04:50.679280Z",
     "start_time": "2020-01-24T22:04:50.662627Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Suggested # of differences (OSCB): {nsdiffs(df['price'], m=12, test='ocsb')}\")\n",
    "print(f\"Suggested # of differences (CH): {nsdiffs(df['price'], m=12, test='ch')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Modeling time series with exponential smoothing methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nasdaqdatalink\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the monthly US unemployment rate from years 2010-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    nasdaqdatalink.get(dataset=\"FRED/UNRATENSA\", \n",
    "                       start_date=\"2010-01-01\", \n",
    "                       end_date=\"2019-12-31\")\n",
    "    .rename(columns={\"Value\": \"unemp_rate\"})\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:25:37.585846Z",
     "start_time": "2020-01-24T22:25:37.582672Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "from statsmodels.tsa.holtwinters import (ExponentialSmoothing, \n",
    "                                         SimpleExpSmoothing, \n",
    "                                         Holt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create the train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:25:42.461469Z",
     "start_time": "2020-01-24T22:25:42.456793Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_LENGTH = 12\n",
    "\n",
    "df.index.freq = \"MS\"\n",
    "\n",
    "df_train = df.iloc[:-TEST_LENGTH]\n",
    "df_test = df.iloc[-TEST_LENGTH:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fit 2 Simple Exponential Smoothing models and create forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:25:52.187062Z",
     "start_time": "2020-01-24T22:25:52.148624Z"
    }
   },
   "outputs": [],
   "source": [
    "ses_1 = SimpleExpSmoothing(df_train).fit(smoothing_level=0.5)\n",
    "ses_forecast_1 = ses_1.forecast(TEST_LENGTH)\n",
    "\n",
    "ses_2 = SimpleExpSmoothing(df_train).fit()\n",
    "ses_forecast_2 = ses_2.forecast(TEST_LENGTH)\n",
    "\n",
    "ses_1.params_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Combine the forecasts with the fitted values and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_df = df.copy()\n",
    "ses_df[\"ses_1\"] = ses_1.fittedvalues.append(ses_forecast_1)\n",
    "ses_df[\"ses_2\"] = ses_2.fittedvalues.append(ses_forecast_2)\n",
    "\n",
    "opt_alpha = ses_2.model.params[\"smoothing_level\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ses_df[\"2017\":].plot(style=[\"-\",\":\",\"--\"], ax=ax,\n",
    "                     title=\"Simple Exponential Smoothing\")\n",
    "labels = [\n",
    "    \"unemp_rate\", \n",
    "    r\"$\\alpha=0.2$\",\n",
    "    r\"$\\alpha={0:.2f}$\".format(opt_alpha), \n",
    "]\n",
    "ax.legend(labels)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_13\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fit 3 variants of Holt's linear trend models and create forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:29:51.093407Z",
     "start_time": "2020-01-24T22:29:50.796751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Holt's model with linear trend\n",
    "hs_1 = Holt(df_train).fit()\n",
    "hs_forecast_1 = hs_1.forecast(TEST_LENGTH)\n",
    "\n",
    "# Holt's model with exponential trend\n",
    "hs_2 = Holt(df_train, exponential=True).fit()\n",
    "# equivalent to ExponentialSmoothing(df_train, trend=\"mul\").fit()\n",
    "hs_forecast_2 = hs_2.forecast(TEST_LENGTH)\n",
    "\n",
    "# Holt's model with exponential trend and damping\n",
    "hs_3 = Holt(df_train, exponential=False, \n",
    "            damped_trend=True).fit()\n",
    "hs_forecast_3 = hs_3.forecast(TEST_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_3.params_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Plot the original series together with the models' forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_df = df.copy()\n",
    "hs_df[\"hs_1\"] = hs_1.fittedvalues.append(hs_forecast_1)\n",
    "hs_df[\"hs_2\"] = hs_2.fittedvalues.append(hs_forecast_2)\n",
    "hs_df[\"hs_3\"] = hs_3.fittedvalues.append(hs_forecast_3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "hs_df[\"2017\":].plot(style=[\"-\",\":\",\"--\", \"-.\"], ax=ax,\n",
    "                    title=\"Holt's Double Exponential Smoothing\")\n",
    "labels = [\n",
    "    \"unemp_rate\", \n",
    "    \"Linear trend\",\n",
    "    \"Exponential trend\",\n",
    "    \"Exponential trend (damped)\",\n",
    "]\n",
    "ax.legend(labels)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_14\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Fit 2 variants of Holt-Winter's Triple Exponential Smoothing models and create forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:36:04.997493Z",
     "start_time": "2020-01-24T22:35:52.736584Z"
    }
   },
   "outputs": [],
   "source": [
    "SEASONAL_PERIODS = 12\n",
    "\n",
    "# Holt-Winters' model with exponential trend\n",
    "hw_1 = ExponentialSmoothing(df_train, \n",
    "                            trend=\"mul\", \n",
    "                            seasonal=\"add\", \n",
    "                            seasonal_periods=SEASONAL_PERIODS).fit()\n",
    "hw_forecast_1 = hw_1.forecast(TEST_LENGTH)\n",
    "\n",
    "# Holt-Winters' model with exponential trend and damping\n",
    "hw_2 = ExponentialSmoothing(df_train, \n",
    "                            trend=\"mul\", \n",
    "                            seasonal=\"add\", \n",
    "                            seasonal_periods=SEASONAL_PERIODS, \n",
    "                            damped_trend=True).fit()\n",
    "hw_forecast_2 = hw_2.forecast(TEST_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_2.params_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Plot the original series together with the models' results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_df = df.copy()\n",
    "hw_df[\"hw_1\"] = hw_1.fittedvalues.append(hw_forecast_1)\n",
    "hw_df[\"hw_2\"] = hw_2.fittedvalues.append(hw_forecast_2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "hw_df[\"2017\":].plot(\n",
    "    style=[\"-\",\":\",\"--\"], ax=ax,\n",
    "    title=\"Holt-Winters' Triple Exponential Smoothing\"\n",
    ")\n",
    "phi = hw_2.model.params[\"damping_trend\"]\n",
    "\n",
    "labels = [\n",
    "    \"unemp_rate\", \n",
    "    \"Seasonal Smoothing\",\n",
    "    f\"Seasonal Smoothing (damped with $\\phi={phi:.2f}$)\"\n",
    "]\n",
    "ax.legend(labels)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_15\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.ets import AutoETS\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit the `AutoETS` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ets = AutoETS(auto=True, n_jobs=-1, sp=12)\n",
    "auto_ets.fit(df_train.to_period())\n",
    "auto_ets_fcst = auto_ets.predict(fh=list(range(1, 13)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ets.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Add the model's forecast to the plot of the Holt-Winters' forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ets_df = hw_df.to_period().copy()\n",
    "auto_ets_df[\"auto_ets\"] = (\n",
    "    auto_ets\n",
    "    ._fitted_forecaster\n",
    "    .fittedvalues\n",
    "    .append(auto_ets_fcst[\"unemp_rate\"])\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "auto_ets_df[\"2017\":].plot(\n",
    "    style=[\"-\",\":\",\"--\",\"-.\"], ax=ax,\n",
    "    title=\"Holt-Winters' models vs. AutoETS\"\n",
    ")\n",
    "labels = [\n",
    "    \"unemp_rate\", \n",
    "    \"Seasonal Smoothing\",\n",
    "    f\"Seasonal Smoothing (damped with $\\phi={phi:.2f}$)\",\n",
    "    \"AutoETS\",\n",
    "]\n",
    "ax.legend(labels)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_16\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calculate the MAPEs of the Holt-Winters' forecasts and the ones from AutoETS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_dict = {\n",
    "    \"Seasonal Smoothing\": hw_forecast_1,\n",
    "    \"Seasonal Smoothing (damped)\": hw_forecast_2,\n",
    "    \"AutoETS\": auto_ets_fcst,\n",
    "}\n",
    "\n",
    "print(\"MAPEs ----\")\n",
    "for key, value in fcst_dict.items():\n",
    "    mape = mean_absolute_percentage_error(df_test, value)\n",
    "    print(f\"{key}: {100 * mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Modeling time series with ARIMA class models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nasdaqdatalink\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the monthly US unemployment rate from years 2010-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    nasdaqdatalink.get(dataset=\"FRED/UNRATENSA\", \n",
    "                       start_date=\"2010-01-01\", \n",
    "                       end_date=\"2019-12-31\")\n",
    "    .rename(columns={\"Value\": \"unemp_rate\"})\n",
    ")\n",
    "\n",
    "# to hide the warnings of `statsmodels`\n",
    "df.index.freq = \"MS\"\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:43:19.099101Z",
     "start_time": "2020-01-24T22:43:19.095870Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from chapter_6_utils import test_autocorrelation\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create the train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_LENGTH = 12\n",
    "df_train = df.iloc[:-TEST_LENGTH]\n",
    "df_test = df.iloc[-TEST_LENGTH:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Apply the log transformation and calculate the first differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"unemp_rate_log\"] = np.log(df_train[\"unemp_rate\"])\n",
    "df_train[\"first_diff\"] = df_train[\"unemp_rate_log\"].diff()\n",
    "\n",
    "df_train.plot(subplots=True, \n",
    "              title=\"Original vs transformed series\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_17\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Test the stationarity of the differenced series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = test_autocorrelation(df_train[\"first_diff\"].dropna())\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_18\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fit two different ARIMA models and print their summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:47:31.888480Z",
     "start_time": "2020-01-24T22:47:31.764293Z"
    }
   },
   "outputs": [],
   "source": [
    "arima_111 = ARIMA(\n",
    "    df_train[\"unemp_rate_log\"], order=(1, 1, 1)\n",
    ").fit()\n",
    "arima_111.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_212 = ARIMA(\n",
    "    df_train[\"unemp_rate_log\"], order=(2, 1, 2)\n",
    ").fit()\n",
    "arima_212.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Combine the fitted values with the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pred_111_log\"] = (\n",
    "    arima_111\n",
    "    .fittedvalues\n",
    "    .append(arima_111.forecast(TEST_LENGTH))\n",
    ")\n",
    "df[\"pred_111\"] = np.exp(df[\"pred_111_log\"])\n",
    "\n",
    "df[\"pred_212_log\"] = (\n",
    "    arima_212\n",
    "    .fittedvalues\n",
    "    .append(arima_212.forecast(TEST_LENGTH))\n",
    ")\n",
    "df[\"pred_212\"] = np.exp(df[\"pred_212_log\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The number of initial periods during which the loglikelihood is not recorded. Default is 0.\n",
    "arima_111.loglikelihood_burn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_111.nobs_diffuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Plot the forecasts and calculate the MAPEs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df[[\"unemp_rate\", \"pred_111\", \"pred_212\"]]\n",
    "    .iloc[1:]\n",
    "    .plot(title=\"ARIMA forecast of the US unemployment rate\")\n",
    ");\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_21\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df[[\"unemp_rate\", \"pred_111\", \"pred_212\"]]\n",
    "    .iloc[-TEST_LENGTH:]\n",
    "    .plot(title=\"Zooming in on the out-of-sample forecast\")\n",
    ");\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_22\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_111 = mean_absolute_percentage_error(\n",
    "    df[\"unemp_rate\"].iloc[-TEST_LENGTH:], \n",
    "    df[\"pred_111\"].iloc[-TEST_LENGTH:]\n",
    ")\n",
    "\n",
    "mape_212 = mean_absolute_percentage_error(\n",
    "    df[\"unemp_rate\"].iloc[-TEST_LENGTH:], \n",
    "    df[\"pred_212\"].iloc[-TEST_LENGTH:]\n",
    ")\n",
    "\n",
    "print(f\"MAPE of ARIMA(1,1,1): {100 * mape_111:.2f}%\")\n",
    "print(f\"MAPE of ARIMA(2,1,2): {100 * mape_212:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Extract the forecast with the corresponding confidence intervals and plot them all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = arima_212.get_forecast(TEST_LENGTH).summary_frame()\n",
    "preds_df.columns = [\"fcst\", \"fcst_se\", \"ci_lower\", \"ci_upper\"]\n",
    "plot_df = df_test[[\"unemp_rate\"]].join(np.exp(preds_df))\n",
    "plot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "(\n",
    "    plot_df[[\"unemp_rate\", \"fcst\"]]\n",
    "    .plot(ax=ax,\n",
    "          title=\"ARIMA(2,1,2) forecast with confidence intervals\")\n",
    ")\n",
    "\n",
    "ax.fill_between(plot_df.index,\n",
    "                plot_df[\"ci_lower\"],\n",
    "                plot_df[\"ci_upper\"],\n",
    "                alpha=0.3, \n",
    "                facecolor=\"g\")\n",
    "\n",
    "ax.legend(loc=\"upper left\");\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_23\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Plot diagnostic plots for the residuals of the fitted ARIMA(2,1,2) model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_212.plot_diagnostics(figsize=(18, 14), lags=25)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_24\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Apply the Ljung-Box's test for no autocorrelation in the residuals and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:47:45.624936Z",
     "start_time": "2020-01-24T22:47:42.391631Z"
    }
   },
   "outputs": [],
   "source": [
    "ljung_box_results = arima_212.test_serial_correlation(method=\"ljungbox\")\n",
    "ljung_box_pvals = ljung_box_results[0][1]\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=[16, 5])\n",
    "sns.scatterplot(x=range(len(ljung_box_pvals)), \n",
    "                y=ljung_box_pvals, \n",
    "                ax=ax)\n",
    "ax.axhline(0.05, ls=\"--\", c=\"r\")\n",
    "ax.set(title=\"Ljung-Box test's results\",\n",
    "       xlabel=\"Lag\",\n",
    "       ylabel=\"p-value\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_25\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative way to get the same test results\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "ljung_box_results_df = acorr_ljungbox(arima_212.resid[1:])\n",
    "ljung_box_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first residual of the fitted ARIMA/ARMA model is equal to the first observation of the time series. For more information, please see the following:\n",
    "* https://stats.stackexchange.com/questions/202903/start-up-values-for-the-kalman-filter/221723#221723"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_212.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other available tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_212.test_normality(method=\"jarquebera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_212.test_heteroskedasticity(method=\"breakvar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Finding the best-fitting ARIMA model with auto-ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nasdaqdatalink\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the monthly US unemployment rate from years 2010-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    nasdaqdatalink.get(dataset=\"FRED/UNRATENSA\", \n",
    "                       start_date=\"2010-01-01\", \n",
    "                       end_date=\"2019-12-31\")\n",
    "    .rename(columns={\"Value\": \"unemp_rate\"})\n",
    ")\n",
    "\n",
    "# to hide the warnings of `statsmodels`\n",
    "df.index.freq = \"MS\"\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:43:19.099101Z",
     "start_time": "2020-01-24T22:43:19.095870Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pmdarima as pm\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create the train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_LENGTH = 12\n",
    "df_train = df.iloc[:-TEST_LENGTH]\n",
    "df_test = df.iloc[-TEST_LENGTH:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Find the best hyperparameters of the ARIMA model using the auto-ARIMA procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima = pm.auto_arima(df_train,\n",
    "                           test=\"adf\",\n",
    "                           seasonal=False,\n",
    "                           with_intercept=False,\n",
    "                           stepwise=True,\n",
    "                           suppress_warnings=True,\n",
    "                           trace=True)\n",
    "                            \n",
    "auto_arima.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima.plot_diagnostics(figsize=(18, 14), lags=25)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_27\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Find the best hyperparameters of a SARIMA model using the auto-ARIMA procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T22:59:29.849437Z",
     "start_time": "2020-01-24T22:59:19.421006Z"
    }
   },
   "outputs": [],
   "source": [
    "auto_sarima = pm.auto_arima(df_train,\n",
    "                            test=\"adf\",\n",
    "                            seasonal=True,\n",
    "                            m=12,\n",
    "                            with_intercept=False,\n",
    "                            stepwise=True,\n",
    "                            suppress_warnings=True,\n",
    "                            trace=True)\n",
    "auto_sarima.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to the following SO question to see why the procedure returns `AIC=inf` for some model specifications:\n",
    "* https://stats.stackexchange.com/questions/160612/auto-arima-doesnt-calculate-aic-values-for-the-majority-of-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_sarima.plot_diagnostics(figsize=(18, 14), lags=25);\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_29\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate the forecasts from the two models and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"auto_arima\"] = auto_arima.predict(TEST_LENGTH)\n",
    "df_test[\"auto_sarima\"] = auto_sarima.predict(TEST_LENGTH)\n",
    "df_test.plot(title=\"Forecasts of the best ARIMA/SARIMA models\");\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_30\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_auto_arima = mean_absolute_percentage_error(\n",
    "    df_test[\"unemp_rate\"], \n",
    "    df_test[\"auto_arima\"]\n",
    ")\n",
    "\n",
    "mape_auto_sarima = mean_absolute_percentage_error(\n",
    "    df_test[\"unemp_rate\"], \n",
    "    df_test[\"auto_sarima\"]\n",
    ")\n",
    "\n",
    "print(f\"MAPE of auto-ARIMA: {100*mape_auto_arima:.2f}%\")\n",
    "print(f\"MAPE of auto-SARIMA: {100*mape_auto_sarima:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.pipeline import Pipeline\n",
    "from pmdarima.preprocessing import FourierFeaturizer\n",
    "from pmdarima.preprocessing import LogEndogTransformer\n",
    "from pmdarima import arima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create new features (month dummies) and split them into the train/test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dummies = pd.get_dummies(\n",
    "    df.index.month, \n",
    "    prefix=\"month_\", \n",
    "    drop_first=True\n",
    ")\n",
    "month_dummies.index = df.index\n",
    "df = df.join(month_dummies)\n",
    "\n",
    "df_train = df.iloc[:-TEST_LENGTH]\n",
    "df_test = df.iloc[-TEST_LENGTH:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Find the best hyperparameters of the ARIMAX model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arimax = pm.auto_arima(\n",
    "    df_train[[\"unemp_rate\"]],\n",
    "    exogenous=df_train.drop(columns=[\"unemp_rate\"]),\n",
    "    test=\"adf\",\n",
    "    seasonal=False,\n",
    "    with_intercept=False,\n",
    "    stepwise=True,\n",
    "    suppress_warnings=True,\n",
    "    trace=True\n",
    ")\n",
    "                            \n",
    "auto_arimax.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arimax.plot_diagnostics(figsize=(18, 14), lags=25);\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_32\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Find the best hyperparameters of the ARIMA pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_pipe = Pipeline([\n",
    "    (\"log_transform\", LogEndogTransformer()),\n",
    "    (\"fourier\", FourierFeaturizer(m=12)),\n",
    "    (\"arima\", arima.AutoARIMA(stepwise=True, trace=1, \n",
    "                              error_action=\"warn\",\n",
    "                              test=\"adf\", seasonal=False, \n",
    "                              with_intercept=False, \n",
    "                              suppress_warnings=True))\n",
    "])\n",
    "\n",
    "auto_arima_pipe.fit(df_train[[\"unemp_rate\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate the forecasts and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify return_conf_int when calling `predict` to get the confidence intervals\n",
    "results_df = df_test[[\"unemp_rate\"]].copy()\n",
    "results_df[\"auto_arimax\"] = auto_arimax.predict(\n",
    "    TEST_LENGTH, \n",
    "    X=df_test.drop(columns=[\"unemp_rate\"])\n",
    ")\n",
    "results_df[\"auto_arima_pipe\"] = auto_arima_pipe.predict(TEST_LENGTH)\n",
    "results_df.plot(title=\"Forecasts of the ARIMAX/pipe models\");\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_6_33\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Calculate the MAPEs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_auto_arimax = mean_absolute_percentage_error(results_df[\"unemp_rate\"], \n",
    "                                                  results_df[\"auto_arimax\"])\n",
    "\n",
    "mape_auto_pipe = mean_absolute_percentage_error(results_df[\"unemp_rate\"], \n",
    "                                                results_df[\"auto_arima_pipe\"])\n",
    "\n",
    "print(f\"MAPE of auto-ARIMAX: {100*mape_auto_arimax:.2f}%\")\n",
    "print(f\"MAPE of auto-pipe: {100*mape_auto_pipe:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0117835dafdb051235b33d006a7ad155411608685e1d44af6fb551f6db3e7774"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "293.297px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
