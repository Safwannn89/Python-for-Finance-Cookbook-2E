{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:24:54.871706Z",
     "start_time": "2020-01-29T15:24:54.859745Z"
    }
   },
   "source": [
    "Please run those two cells before running the Notebook!\n",
    "\n",
    "As those plotting settings are standard throughout the book, we do not show them in the book every time we plot something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:24:55.068103Z",
     "start_time": "2020-01-29T15:24:55.064292Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "# FIX: Use the official public API path from pandas.errors\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "# feel free to modify, for example, change the context to \"notebook\"\n",
    "sns.set_theme(context=\"talk\", style=\"whitegrid\", \n",
    "              palette=\"colorblind\", color_codes=True, \n",
    "              rc={\"figure.figsize\": [12, 8]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13 - Applied Machine Learning: Identifying Credit Default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 13.0 Getting and preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is a part not covered in the book. We download the considered dataset from the website of the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients). The dataset originally does not contain missing values and the categorical variables are already encoded as numbers. To show the entire pipeline of working and preparing potentially messy data, we apply some transformations:\n",
    "\n",
    "* we encoded the gender, education and marital status related variables to strings\n",
    "* we introduced missing values to some observations (0.5% of the entire sample, selected randomly per column - the total percentage of rows with at least one missing value will be higher)\n",
    "* some observed values for features such as level of education, payment status, etc. are outside of the range of possible categories defined by the authors. As this problem affects many observations, we encode new, undescribed categories as either 'Others' (when there was already such a category) or 'Unknown' (in the case of payment status).\n",
    "\n",
    "The reason for selecting only a small fraction of values to be missing is that we do not want to significantly change the underlying structure/patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:53:50.719237Z",
     "start_time": "2020-01-22T17:53:50.471205Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: Use conda to force a clean reinstall of numpy and install TA-Lib\n",
    "!conda install --yes -c conda-forge numpy=1.26.4 ta-lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install --yes -c conda-forge numpy xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:53:51.141373Z",
     "start_time": "2020-01-22T17:53:51.139223Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# FIX: Use pandas to read the Excel file directly from the URL\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls'\n",
    "\n",
    "# The actual data in this file starts on the second row, so we use header=1\n",
    "df = pd.read_excel(url, header=1)\n",
    "\n",
    "# You can add a .head() call to see the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:46:22.737466Z",
     "start_time": "2019-10-29T16:46:20.151921Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data from Excel\n",
    "df = pd.read_excel(\"default of credit card clients.xls\", skiprows=1, index_col=0)\n",
    "\n",
    "# rename columns\n",
    "df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "months = [\"sep\", \"aug\", \"jul\", \"jun\", \"may\", \"apr\"]\n",
    "variables = [\"payment_status\", \"bill_statement\", \"previous_payment\"]\n",
    "new_column_names = [x + \"_\" + y for x in variables for y in months]\n",
    "rename_dict = {x: y for x, y in zip(df.loc[:, \"pay_0\":\"pay_amt6\"].columns, new_column_names)}\n",
    "df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "\n",
    "# create dicts to map number to strings\n",
    "gender_dict = {1: \"Male\", \n",
    "               2: \"Female\"}\n",
    "education_dict = {0: \"Others\",\n",
    "                  1: \"Graduate school\", \n",
    "                  2: \"University\", \n",
    "                  3: \"High school\", \n",
    "                  4: \"Others\",\n",
    "                  5: \"Others\",\n",
    "                  6: \"Others\"}\n",
    "marital_status_dict = {0: \"Others\", \n",
    "                       1: \"Married\", \n",
    "                       2: \"Single\", \n",
    "                       3: \"Others\"}\n",
    "payment_status = {-2: \"Unknown\",\n",
    "                  -1: \"Payed duly\",\n",
    "                  0: \"Unknown\",\n",
    "                  1: \"Payment delayed 1 month\",\n",
    "                  2: \"Payment delayed 2 months\",\n",
    "                  3: \"Payment delayed 3 months\",\n",
    "                  4: \"Payment delayed 4 months\",\n",
    "                  5: \"Payment delayed 5 months\",\n",
    "                  6: \"Payment delayed 6 months\",\n",
    "                  7: \"Payment delayed 7 months\",\n",
    "                  8: \"Payment delayed 8 months\",\n",
    "                  9: \"Payment delayed >= 9 months\"}\n",
    "\n",
    "# map numbers to strings\n",
    "df[\"sex\"] = df[\"sex\"].map(gender_dict)\n",
    "df[\"education\"] = df[\"education\"].map(education_dict)\n",
    "df[\"marriage\"] = df[\"marriage\"].map(marital_status_dict)\n",
    "\n",
    "for column in [x for x in df.columns if (\"status\" in x)]:\n",
    "    df[column] = df[column].map(payment_status)\n",
    "\n",
    "# define the ratio of missing values\n",
    "RATIO_MISSING = 0.005\n",
    "\n",
    "# input missing values to selected columns\n",
    "random_state = np.random.RandomState(42)\n",
    "for column in [\"sex\", \"education\", \"marriage\", \"age\"]:\n",
    "    df.loc[df.sample(frac=RATIO_MISSING, random_state=random_state).index, column] = \"\"\n",
    "\n",
    "# reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# save to csv\n",
    "df.to_csv(\"../Datasets/credit_card_default.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1 Loading data and managing data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T12:41:36.224347Z",
     "start_time": "2020-01-30T12:41:36.221580Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the data from the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T12:41:40.642527Z",
     "start_time": "2020-01-30T12:41:40.499516Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Datasets/credit_card_default.csv\", \n",
    "                 na_values=\"\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. View the summary of the DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:03.918461Z",
     "start_time": "2020-01-28T13:03:03.912940Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define a function for inspecting the exact memory usage of a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:04.253016Z",
     "start_time": "2020-01-28T13:03:04.248523Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_df_memory_usage(df, top_columns=5):\n",
    "    \"\"\"\n",
    "    Function for quick analysis of a pandas DataFrame's memory usage.\n",
    "    It prints the top `top_columns` columns in terms of memory usage \n",
    "    and the total usage of the DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame to be inspected\n",
    "    top_columns : int\n",
    "        Number of top columns (in terms of memory used) to display\n",
    "    \"\"\"\n",
    "    print(\"Memory usage ----\")\n",
    "    memory_per_column = df.memory_usage(deep=True) / (1024 ** 2)\n",
    "    print(f\"Top {top_columns} columns by memory (MB):\")\n",
    "    print(memory_per_column.sort_values(ascending=False) \\\n",
    "                           .head(top_columns))\n",
    "    print(f\"Total size: {memory_per_column.sum():.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:04.727029Z",
     "start_time": "2020-01-28T13:03:04.579331Z"
    }
   },
   "outputs": [],
   "source": [
    "get_df_memory_usage(df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Convert the columns with `object` data type into `category` type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:04.936696Z",
     "start_time": "2020-01-28T13:03:04.890750Z"
    }
   },
   "outputs": [],
   "source": [
    "object_columns = df.select_dtypes(include=\"object\").columns\n",
    "df[object_columns] = df[object_columns].astype(\"category\")\n",
    "\n",
    "get_df_memory_usage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Downcast the numeric columns to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=\"number\").columns\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "\n",
    "get_df_memory_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Downcast the `age` column using the `float` data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"] = pd.to_numeric(df[\"age\"], downcast=\"float\")\n",
    "\n",
    "get_df_memory_usage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the data types to columns while loading the data using the `pd.read_csv`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:05.633345Z",
     "start_time": "2020-01-28T13:03:05.506769Z"
    }
   },
   "outputs": [],
   "source": [
    "column_dtypes = {\n",
    "    \"education\": \"category\", \n",
    "    \"marriage\": \"category\", \n",
    "    \"sex\": \"category\"\n",
    "}\n",
    "df_cat = pd.read_csv(\"../Datasets/credit_card_default.csv\", \n",
    "                     na_values=\"\", dtype=column_dtypes)\n",
    "\n",
    "get_df_memory_usage(df_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2 Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../Datasets/credit_card_default.csv\", na_values=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T21:24:28.121629Z",
     "start_time": "2019-10-26T21:24:28.117486Z"
    }
   },
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T11:29:26.347585Z",
     "start_time": "2020-01-28T11:29:25.123414Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get summary statistics of the numeric variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:54:30.435731Z",
     "start_time": "2020-01-22T17:54:30.384308Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe().transpose().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Get summary statistics of the categorical variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:54:30.972666Z",
     "start_time": "2020-01-22T17:54:30.908486Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe(include=\"object\").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can get the summary statistics of all columns in one table using the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Plot the distribution of age and, additionally, split it by gender: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(data=df, x=\"age\", \n",
    "                 hue=\"sex\", common_norm=False, \n",
    "                 fill=True)\n",
    "ax.set_title(\"Distribution of age\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_1\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the text, we can create a histogram (together with the KDE), by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(data=df.dropna(), x=\"age\", hue=\"sex\", kde=True)\n",
    "ax.set_title(\"Distribution of age\");\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed some gaps in the plot and the reason for this is the binning. Below, we created the same histogram using `sns.countplot` and `plotly_express`. By doing so, each value of age has a separate bin and we can inspect the plot in detail. There are no such spikes in the following plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df.dropna(), x=\"age\", color=\"b\")\n",
    "\n",
    "for ind, label in enumerate(ax.get_xticklabels()):\n",
    "    if int(float(label.get_text())) % 10 == 0:\n",
    "        label.set_visible(True)\n",
    "    else:\n",
    "        label.set_visible(False)\n",
    "\n",
    "ax.set_title(\"Histogram of age\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:55:08.261624Z",
     "start_time": "2020-01-22T17:55:04.698261Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df.dropna(), x=\"age\", hue=\"sex\")\n",
    "\n",
    "for ind, label in enumerate(ax.get_xticklabels()):\n",
    "    if int(float(label.get_text())) % 10 == 0:\n",
    "        label.set_visible(True)\n",
    "    else:\n",
    "        label.set_visible(False)\n",
    "\n",
    "ax.set_title(\"Histogram of age by gender\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T21:06:10.343469Z",
     "start_time": "2019-12-08T21:06:09.270174Z"
    }
   },
   "outputs": [],
   "source": [
    "px.histogram(df.dropna(), x=\"age\", color=\"sex\", title = \"Distribution of age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"].plot(kind=\"hist\", title=\"Distribution of age\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a `pairplot` of selected variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:55:35.820357Z",
     "start_time": "2020-01-22T17:55:16.118022Z"
    }
   },
   "outputs": [],
   "source": [
    "COLS_TO_PLOT = [\"age\", \"limit_bal\", \"previous_payment_sep\"]\n",
    "\n",
    "pair_plot = sns.pairplot(df[COLS_TO_PLOT], kind=\"reg\", \n",
    "                         diag_kind=\"kde\", height=4,\n",
    "                         plot_kws={\"line_kws\":{\"color\":\"red\"}})\n",
    "pair_plot.fig.suptitle(\"Pairplot of selected variables\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_2\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can separate the genders by specifying the `hue` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_plot = sns.pairplot(data=df, \n",
    "                         x_vars=COLS_TO_PLOT, \n",
    "                         y_vars=COLS_TO_PLOT, \n",
    "                         hue=\"sex\", \n",
    "                         height=4)\n",
    "pair_plot.fig.suptitle(\"Pairplot of selected variables\")\n",
    "plt.subplots_adjust(top=0.95)\n",
    "\n",
    "# plt.savefig(\"images/figure_13_3\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Analyze the relationship between age and limit balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.jointplot(data=df, x=\"age\", y=\"limit_bal\", \n",
    "                   hue=\"sex\", height=10)\n",
    "ax.fig.suptitle(\"Age vs. limit balance\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_4\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Define and run a function for plotting the correlation heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:56:07.556117Z",
     "start_time": "2020-01-22T17:56:07.549240Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(corr_mat, annotate=False):\n",
    "    \"\"\"\n",
    "    Function for plotting the correlation heatmap. It masks the irrelevant fields.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corr_mat : pd.DataFrame\n",
    "        Correlation matrix of the features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # temporarily change style\n",
    "    sns.set(style=\"white\")\n",
    "    # mask the upper triangle\n",
    "    mask = np.zeros_like(corr_mat, dtype=bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    # set up the matplotlib figure\n",
    "    fig, ax = plt.subplots()\n",
    "    # set up custom diverging colormap\n",
    "    cmap = sns.diverging_palette(240, 10, n=9, as_cmap=True)\n",
    "    # plot the heatmap\n",
    "    sns.heatmap(corr_mat, mask=mask, cmap=cmap, \n",
    "                annot=annotate, vmax=.3, \n",
    "                center=0, square=True, linewidths=.5, \n",
    "                cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "    ax.set_title(\"Correlation Matrix\", fontsize=16)\n",
    "    # change back to darkgrid style\n",
    "    sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T21:13:16.995297Z",
     "start_time": "2019-12-08T21:13:13.456922Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_mat = df.select_dtypes(include=\"number\").corr()    \n",
    "plot_correlation_matrix(corr_mat)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_5\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also directly inspect the correlation between the features (numerical) and the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:56:14.630145Z",
     "start_time": "2020-01-22T17:56:14.601671Z"
    }
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(include=\"number\").corr()[[\"default_payment_next_month\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Analyze the distribution of age in groups using boxplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=df, y=\"age\", x=\"marriage\", hue=\"sex\");\n",
    "ax.set_title(\"Distribution of age\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_6\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Plot the distribution of limit balance for each gender and education level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:56:30.022284Z",
     "start_time": "2020-01-22T17:56:25.037383Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"education\", y=\"limit_bal\", \n",
    "                    hue=\"sex\", split=True, data=df)\n",
    "ax.set_title(\n",
    "    \"Distribution of limit balance per education level\", \n",
    "    fontsize=16\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_7\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the same information, without splitting the violin plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T11:58:22.541157Z",
     "start_time": "2020-01-28T11:58:22.538964Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"education\", y=\"limit_bal\", \n",
    "                    hue=\"sex\", data=df)\n",
    "ax.set_title(\"Distribution of limit balance per education level\", \n",
    "             fontsize=16)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Investigate the distribution of the target variable per gender and education level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:56:49.986435Z",
     "start_time": "2020-01-22T17:56:45.478524Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(\"default_payment_next_month\", hue=\"sex\", \n",
    "                   data=df, orient=\"h\")\n",
    "ax.set_title(\"Distribution of the target variable\", fontsize=16)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_8\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Investigate the percentage of defaults per education level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:57:22.332830Z",
     "start_time": "2020-01-22T17:57:17.943425Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = df.groupby(\"education\")[\"default_payment_next_month\"] \\\n",
    "       .value_counts(normalize=True) \\\n",
    "       .unstack() \\\n",
    "       .plot(kind=\"barh\", stacked=True)\n",
    "ax.set_title(\"Percentage of defaults per education level\", \n",
    "             fontsize=16)\n",
    "ax.legend(title=\"Default\", bbox_to_anchor=(1,1)) \n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_9\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T21:07:05.751821Z",
     "start_time": "2019-12-08T21:06:45.090668Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title=\"Loan Default Dataset EDA\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(\"loan_default_eda.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.3 Splitting the data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../Datasets/credit_card_default.csv\", na_values=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:11.188739Z",
     "start_time": "2020-01-28T13:03:10.701780Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Separate the target from the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(\"default_payment_next_month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split the data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T12:28:13.909098Z",
     "start_time": "2020-01-28T12:28:13.898473Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Split the data into training and test sets without shuffling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T12:28:14.235010Z",
     "start_time": "2020-01-28T12:28:14.225616Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Split the data into training and test sets with stratification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:12.841474Z",
     "start_time": "2020-01-28T13:03:12.818558Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Verify that the ratio of the target is preserved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target distribution - train\")\n",
    "print(y_train.value_counts(normalize=True).values)\n",
    "print(\"Target distribution - test\")\n",
    "print(y_test.value_counts(normalize=True).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T12:28:16.424492Z",
     "start_time": "2020-01-28T12:28:16.396682Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define the size of the validation and test sets\n",
    "VALID_SIZE = 0.1\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# create the initial split - training and temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, \n",
    "    test_size=(VALID_SIZE + TEST_SIZE), \n",
    "    stratify=y, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# calculate the new test size\n",
    "new_test_size = np.around(TEST_SIZE / (VALID_SIZE + TEST_SIZE), 2)\n",
    "\n",
    "# create the valid and test sets\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=new_test_size, \n",
    "    stratify=y_temp, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of data in each set ----\")\n",
    "print(f\"Train: {100 * len(X_train) / len(X):.2f}%\")\n",
    "print(f\"Valid: {100 * len(X_valid) / len(X):.2f}%\")\n",
    "print(f\"Test: {100 * len(X_test) / len(X):.2f}%\")\n",
    "print(\"\")\n",
    "print(\"Class distribution in each set ----\")\n",
    "print(f\"Train: {y_train.value_counts(normalize=True).values}\")\n",
    "print(f\"Valid: {y_valid.value_counts(normalize=True).values}\")\n",
    "print(f\"Test: {y_test.value_counts(normalize=True).values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.4 Identifying and dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:17.069179Z",
     "start_time": "2020-01-28T13:03:16.924911Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import missingno as msno\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Inspect the information about the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:17.652101Z",
     "start_time": "2020-01-28T13:03:17.635968Z"
    }
   },
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Visualize the nullity of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:48.194879Z",
     "start_time": "2020-01-28T13:03:18.095991Z"
    }
   },
   "outputs": [],
   "source": [
    "msno.matrix(X)\n",
    "\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_13_12\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T16:24:34.598422Z",
     "start_time": "2019-11-06T16:24:34.594572Z"
    }
   },
   "source": [
    "4. Define columns with missing values per data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:48.644046Z",
     "start_time": "2020-01-28T13:03:48.641316Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_FEATURES = [\"age\"]\n",
    "CAT_FEATURES = [\"sex\", \"education\", \"marriage\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Impute the numerical feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:49.138688Z",
     "start_time": "2020-01-28T13:03:49.119231Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in NUM_FEATURES:\n",
    "    num_imputer = SimpleImputer(strategy=\"median\")\n",
    "    num_imputer.fit(X_train[[col]])\n",
    "    X_train.loc[:, col] = num_imputer.transform(X_train[[col]])\n",
    "    X_test.loc[:, col] = num_imputer.transform(X_test[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:49.589039Z",
     "start_time": "2020-01-28T13:03:49.586856Z"
    }
   },
   "outputs": [],
   "source": [
    "# alternative method using pandas\n",
    "\n",
    "# for feature in NUM_FEATURES:\n",
    "#     median_value = X_train[feature].median()\n",
    "#     X_train.loc[:, feature].fillna(median_value, inplace=True)\n",
    "#     X_test.loc[:, feature].fillna(median_value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Impute the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:50.373245Z",
     "start_time": "2020-01-28T13:03:50.037148Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in CAT_FEATURES:\n",
    "    cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    cat_imputer.fit(X_train[[col]])\n",
    "    X_train.loc[:, col] = cat_imputer.transform(X_train[[col]])\n",
    "    X_test.loc[:, col] = cat_imputer.transform(X_test[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:50.832783Z",
     "start_time": "2020-01-28T13:03:50.830406Z"
    }
   },
   "outputs": [],
   "source": [
    "# alternative method using pandas\n",
    "\n",
    "# for feature in CAT_FEATURES:\n",
    "#     mode_value = X_train[feature].mode().values[0]\n",
    "#     X_train.loc[:, feature].fillna(mode_value, inplace=True)\n",
    "#     X_test.loc[:, feature].fillna(mode_value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T08:00:57.060642Z",
     "start_time": "2019-11-06T08:00:57.056765Z"
    }
   },
   "source": [
    "7. Verify that there are no missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:03:51.302491Z",
     "start_time": "2020-01-28T13:03:51.287315Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also look into the other types of visualizations offered by `missingno`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(X)\n",
    "\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(X)\n",
    "\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.dendrogram(X)\n",
    "\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_13_13\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.5 Encoding categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:39:57.777751Z",
     "start_time": "2020-01-28T13:39:57.775233Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use Label Encoder to encode a selected column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:39:58.880522Z",
     "start_time": "2020-01-28T13:39:58.867488Z"
    }
   },
   "outputs": [],
   "source": [
    "COL = \"education\"\n",
    "\n",
    "X_train_copy = X_train.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "label_enc.fit(X_train_copy[COL])\n",
    "X_train_copy.loc[:, COL] = label_enc.transform(X_train_copy[COL])\n",
    "X_test_copy.loc[:, COL] = label_enc.transform(X_test_copy[COL])\n",
    "\n",
    "X_test_copy[COL].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Select categorical features for one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:39:59.656199Z",
     "start_time": "2020-01-28T13:39:59.647502Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_features = X_train.select_dtypes(include=\"object\") \\\n",
    "                      .columns \\\n",
    "                      .to_list()\n",
    "\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Instantiate the `OneHotEncoder` object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:40:00.326113Z",
     "start_time": "2020-01-28T13:40:00.323060Z"
    }
   },
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse=False, \n",
    "                                handle_unknown=\"error\", \n",
    "                                drop=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create the column transformer using the one-hot encoder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:40:00.938188Z",
     "start_time": "2020-01-28T13:40:00.935516Z"
    }
   },
   "outputs": [],
   "source": [
    "one_hot_transformer = ColumnTransformer(\n",
    "    [(\"one_hot\", one_hot_encoder, cat_features)],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Fit the transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:40:01.608570Z",
     "start_time": "2020-01-28T13:40:01.536852Z"
    }
   },
   "outputs": [],
   "source": [
    "one_hot_transformer.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Apply the transformations to both training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:40:02.333411Z",
     "start_time": "2020-01-28T13:40:02.200486Z"
    }
   },
   "outputs": [],
   "source": [
    "col_names = one_hot_transformer.get_feature_names_out()\n",
    "\n",
    "X_train_ohe = pd.DataFrame(one_hot_transformer.transform(X_train), \n",
    "                           columns=col_names, \n",
    "                           index=X_train.index)\n",
    "\n",
    "X_test_ohe = pd.DataFrame(one_hot_transformer.transform(X_test), \n",
    "                          columns=col_names, \n",
    "                          index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see how one-hot encoding increased the shape of our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe.to_csv(\"X_train_ohe.csv\", index=True)\n",
    "X_test_ohe.to_csv(\"X_test_ohe.csv\", index=True)\n",
    "y_train.to_csv(\"y_train.csv\", index=True)\n",
    "y_test.to_csv(\"y_test.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `pandas` for one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:59:14.125399Z",
     "start_time": "2020-01-22T17:59:14.068336Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(X_train, prefix_sep=\"_\", drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying possible categories for OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:59:15.481593Z",
     "start_time": "2020-01-22T17:59:15.465290Z"
    }
   },
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(\n",
    "    categories=[[\"Male\", \"Female\", \"Unknown\"]], \n",
    "    sparse=False, \n",
    "    handle_unknown=\"error\", \n",
    "    drop=\"first\"\n",
    ")\n",
    "\n",
    "one_hot_transformer = ColumnTransformer(\n",
    "    [(\"one_hot\", one_hot_encoder, [\"sex\"])]\n",
    ")\n",
    "\n",
    "one_hot_transformer.fit(X_train)\n",
    "one_hot_transformer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category Encoders library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:59:17.971296Z",
     "start_time": "2020-01-22T17:59:17.928991Z"
    }
   },
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:59:19.127158Z",
     "start_time": "2020-01-22T17:59:19.124290Z"
    }
   },
   "outputs": [],
   "source": [
    "one_hot_encoder_ce = ce.OneHotEncoder(use_cat_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T17:59:20.754284Z",
     "start_time": "2020-01-22T17:59:20.263643Z"
    }
   },
   "outputs": [],
   "source": [
    "one_hot_encoder_ce.fit(X_train)\n",
    "X_train_ce = one_hot_encoder_ce.transform(X_train)\n",
    "X_train_ce.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing the `category` encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dtypes = {\n",
    "    \"education\": \"category\", \n",
    "    \"marriage\": \"category\", \n",
    "    \"sex\": \"category\"\n",
    "}\n",
    "df_cat = pd.read_csv(\"../Datasets/credit_card_default.csv\", \n",
    "                     na_values=\"\", dtype=column_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat[\"education\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(df_cat[\"education\"].cat.codes, df_cat[\"education\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.6 Fitting a decision tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_train_ohe = pd.read_csv(\"X_train_ohe.csv\", index_col=0)\n",
    "X_test_ohe = pd.read_csv(\"X_test_ohe.csv\", index_col=0)\n",
    "y_train = pd.read_csv(\"y_train.csv\", index_col=0)[\"default_payment_next_month\"]\n",
    "y_test = pd.read_csv(\"y_test.csv\", index_col=0)[\"default_payment_next_month\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:40:07.284699Z",
     "start_time": "2020-01-28T13:40:07.281205Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import metrics\n",
    "\n",
    "from chapter_13_utils import performance_evaluation_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create the instance of the model, fit it to the training data and create prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:40:08.861412Z",
     "start_time": "2020-01-28T13:40:08.333620Z"
    }
   },
   "outputs": [],
   "source": [
    "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier.fit(X_train_ohe, y_train)\n",
    "y_pred = tree_classifier.predict(X_test_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluate the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:40:19.011916Z",
     "start_time": "2020-01-28T13:40:10.691002Z"
    }
   },
   "outputs": [],
   "source": [
    "LABELS = [\"No Default\", \"Default\"]\n",
    "tree_perf = performance_evaluation_report(tree_classifier, \n",
    "                                          X_test_ohe, \n",
    "                                          y_test, labels=LABELS, \n",
    "                                          show_plot=True)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_15\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:40:19.834306Z",
     "start_time": "2020-01-28T13:40:19.829937Z"
    }
   },
   "outputs": [],
   "source": [
    "tree_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Plot the first few levels of the fitted decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T18:02:40.136958Z",
     "start_time": "2020-01-22T18:02:39.213199Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_tree(tree_classifier, max_depth=3, fontsize=10)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_16\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(\n",
    "    tree_classifier, \n",
    "    max_depth=2,\n",
    "    feature_names = X_train_ohe.columns, \n",
    "    class_names=[\"No default\", \"Default\"],\n",
    "    rounded=True, \n",
    "    filled = True, \n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_17\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision-recall curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:47:43.430290Z",
     "start_time": "2020-01-28T13:47:43.425430Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_prob = tree_classifier.predict_proba(X_test_ohe)[:, 1]\n",
    "\n",
    "precision, recall, _ = metrics.precision_recall_curve(y_test, \n",
    "                                                      y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:47:53.269588Z",
     "start_time": "2020-01-28T13:47:49.719448Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "ax.plot(recall, precision, \n",
    "        label=f\"PR-AUC = {metrics.auc(recall, precision):.2f}\")\n",
    "ax.set(title=\"Precision-Recall Curve\", \n",
    "       xlabel=\"Recall\", \n",
    "       ylabel=\"Precision\")\n",
    "ax.legend()\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_19\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = metrics.PrecisionRecallDisplay.from_estimator(\n",
    "    tree_classifier, X_test_ohe, y_test\n",
    ")\n",
    "ax.ax_.set_title(\"Precision-Recall Curve\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_20\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing decision trees using `dtreeviz`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.trees import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit a small decision tree with max depth of 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_tree = DecisionTreeClassifier(max_depth=3, \n",
    "                                    random_state=42)\n",
    "small_tree.fit(X_train_ohe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(small_tree, max_depth=3, fontsize=10)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Plot the decision tree using `dtreeviz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = dtreeviz(small_tree, \n",
    "               x_data=X_train_ohe,\n",
    "               y_data=y_train,\n",
    "               feature_names=X_train_ohe.columns, \n",
    "               target_name=\"Default\",\n",
    "               class_names=[\"No\", \"Yes\"], \n",
    "               title=\"Decision Tree - Loan default data set\")\n",
    "viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Plot the simplified tree representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = dtreeviz(small_tree, \n",
    "               x_data=X_train_ohe,\n",
    "               y_data=y_train,\n",
    "               feature_names=X_train_ohe.columns, \n",
    "               target_name=\"Default\",\n",
    "               class_names=[\"No\", \"Yes\"], \n",
    "               title=\"Decision Tree - Loan default data set\",\n",
    "               fancy=False)\n",
    "viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Plot the simplified tree representation and the decision path of the first observation from the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = dtreeviz(small_tree, \n",
    "               x_data=X_train_ohe,\n",
    "               y_data=y_train,\n",
    "               feature_names=X_train_ohe.columns, \n",
    "               target_name=\"Default\",\n",
    "               class_names=[\"No\", \"Yes\"], \n",
    "               title=\"Decision Tree - Loan default data set\",\n",
    "               fancy=False,\n",
    "               X=X_test_ohe.iloc[0])\n",
    "viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Print the prediction path using words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explain_prediction_path(small_tree, X_test_ohe.iloc[0], \n",
    "                              feature_names=X_test_ohe.columns, \n",
    "                              explanation_type=\"plain_english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.7 Organizing the project with pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:24:43.827418Z",
     "start_time": "2020-01-29T15:24:41.858828Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from chapter_13_utils import performance_evaluation_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T15:19:54.078643Z",
     "start_time": "2019-11-11T15:19:54.067379Z"
    }
   },
   "source": [
    "2. Load the data, separate the target and create the stratified train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:24:43.978688Z",
     "start_time": "2020-01-29T15:24:43.836005Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Datasets/credit_card_default.csv\", na_values=\"\")\n",
    "\n",
    "X = df.copy()\n",
    "y = X.pop(\"default_payment_next_month\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepare lists of numerical/categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:24:44.086990Z",
     "start_time": "2020-01-29T15:24:44.072526Z"
    }
   },
   "outputs": [],
   "source": [
    "num_features = X_train.select_dtypes(include=\"number\") \\\n",
    "                      .columns \\\n",
    "                      .to_list()\n",
    "cat_features = X_train.select_dtypes(include=\"object\") \\\n",
    "                      .columns \\\n",
    "                      .to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that all columns are included in the lists\n",
    "len(X_train.columns) == (len(num_features) + len(cat_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T08:13:23.093498Z",
     "start_time": "2019-11-12T08:13:23.090073Z"
    }
   },
   "source": [
    "4. Define the numerical pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:24:44.162700Z",
     "start_time": "2020-01-29T15:24:44.159583Z"
    }
   },
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define the categorical pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:24:44.292208Z",
     "start_time": "2020-01-29T15:24:44.262362Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_list = [\n",
    "    list(X_train[col].dropna().unique()) for col in cat_features\n",
    "]\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(categories=cat_list, \n",
    "                             sparse=False, \n",
    "                             handle_unknown=\"error\", \n",
    "                             drop=\"first\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Define the `ColumnTransformer` object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:24:44.602711Z",
     "start_time": "2020-01-29T15:24:44.599030Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical\", num_pipeline, num_features),\n",
    "        (\"categorical\", cat_pipeline, cat_features)\n",
    "    ], \n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Define the full pipeline including the decision tree model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:24:45.201213Z",
     "start_time": "2020-01-29T15:24:45.197800Z"
    }
   },
   "outputs": [],
   "source": [
    "dec_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "tree_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", dec_tree)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Fit the pipeline to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:24:47.728093Z",
     "start_time": "2020-01-29T15:24:45.949527Z"
    }
   },
   "outputs": [],
   "source": [
    "tree_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Evaluate the performance of the entire pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:25:07.454718Z",
     "start_time": "2020-01-29T15:24:58.918601Z"
    }
   },
   "outputs": [],
   "source": [
    "LABELS = [\"No Default\", \"Default\"]\n",
    "tree_perf = performance_evaluation_report(tree_pipeline, X_test, \n",
    "                                          y_test, labels=LABELS, \n",
    "                                          show_plot=True)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_23\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:23:51.614317Z",
     "start_time": "2020-01-28T16:23:51.610525Z"
    }
   },
   "outputs": [],
   "source": [
    "tree_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding custom transformers to a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the base estimator and transformer classes from `sklearn`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:25:07.616628Z",
     "start_time": "2020-01-29T15:25:07.612406Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define the `OutlierRemover` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:25:07.774148Z",
     "start_time": "2020-01-29T15:25:07.766116Z"
    }
   },
   "outputs": [],
   "source": [
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_std=3):\n",
    "        self.n_std = n_std\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        if np.isnan(X).any(axis=None):\n",
    "            raise ValueError(\"\"\"There are missing values in the array! \n",
    "                                Please remove them.\"\"\")\n",
    "\n",
    "        mean_vec = np.mean(X, axis=0)\n",
    "        std_vec = np.std(X, axis=0)\n",
    "        \n",
    "        self.upper_band_ = pd.Series(mean_vec + self.n_std * std_vec)\n",
    "        self.upper_band_ = self.upper_band_.to_frame().transpose()\n",
    "        self.lower_band_ = pd.Series(mean_vec - self.n_std * std_vec)\n",
    "        self.lower_band_ = self.lower_band_.to_frame().transpose()\n",
    "        self.n_features_ = len(self.upper_band_.columns)\n",
    "        \n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X_copy = pd.DataFrame(X.copy())\n",
    "        \n",
    "        upper_band = pd.concat(\n",
    "            [self.upper_band_] * len(X_copy), \n",
    "            ignore_index=True\n",
    "        )\n",
    "        lower_band = pd.concat(\n",
    "            [self.lower_band_] * len(X_copy), \n",
    "            ignore_index=True\n",
    "        )\n",
    "        \n",
    "        X_copy[X_copy >= upper_band] = upper_band\n",
    "        X_copy[X_copy <= lower_band] = lower_band\n",
    "        \n",
    "        return X_copy.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Add the `OutlierRemover` to the numerical pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:25:07.908147Z",
     "start_time": "2020-01-29T15:25:07.904689Z"
    }
   },
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"outliers\", OutlierRemover())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Execute the rest of the pipeline to compare the results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:25:18.162240Z",
     "start_time": "2020-01-29T15:25:08.037087Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"numerical\", num_pipeline, num_features),\n",
    "    (\"categorical\", cat_pipeline, cat_features)],\n",
    "    remainder=\"drop\")\n",
    "\n",
    "dec_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "tree_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                                (\"classifier\", dec_tree)])\n",
    "\n",
    "tree_pipeline.fit(X_train, y_train)\n",
    "\n",
    "tree_perf = performance_evaluation_report(tree_pipeline, X_test, \n",
    "                                          y_test, labels=LABELS, \n",
    "                                          show_plot=True)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_24\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:24:02.808808Z",
     "start_time": "2020-01-28T16:24:02.804668Z"
    }
   },
   "outputs": [],
   "source": [
    "tree_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing the elements of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Display the structure of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pipeline.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Access the estimator at the end of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pipeline.named_steps[\"classifier\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Access the upper thresholds of the fitted `OutlierRemover` transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    tree_pipeline\n",
    "    .named_steps[\"preprocessor\"]\n",
    "    .named_transformers_[\"numerical\"][\"outliers\"]\n",
    "    .upper_band_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( \n",
    "    tree_pipeline\n",
    "    .named_steps[\"preprocessor\"]\n",
    "    .transformers_[0][1][\"outliers\"]\n",
    "    .upper_band_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.8 Tuning hyperparameters using grid search and cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please execute the code from the previous recipe before running this one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:24:40.175578Z",
     "start_time": "2020-01-28T16:24:40.172150Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GridSearchCV, cross_val_score, \n",
    "    RandomizedSearchCV, cross_validate, \n",
    "    StratifiedKFold\n",
    ")\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define the cross-validation scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:24:41.175443Z",
     "start_time": "2020-01-28T16:24:41.172637Z"
    }
   },
   "outputs": [],
   "source": [
    "k_fold = StratifiedKFold(5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluate the pipeline using cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:24:46.987870Z",
     "start_time": "2020-01-28T16:24:41.611076Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_val_score(tree_pipeline, X_train, y_train, cv=k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Add extra metrics to cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:25:05.879676Z",
     "start_time": "2020-01-28T16:24:59.127144Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_scores = cross_validate(tree_pipeline, X_train, y_train, cv=k_fold, \n",
    "                           scoring=[\"accuracy\", \"precision\", \"recall\", \n",
    "                                    \"roc_auc\"])\n",
    "pd.DataFrame(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define the parameter grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:25:06.004404Z",
     "start_time": "2020-01-28T16:25:06.001060Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"classifier__criterion\": [\"entropy\", \"gini\"],\n",
    "    \"classifier__max_depth\": range(3, 11),\n",
    "    \"classifier__min_samples_leaf\": range(2, 11), \n",
    "    \"preprocessor__numerical__outliers__n_std\": [3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Run the exhaustive grid search: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:31:31.961367Z",
     "start_time": "2020-01-28T16:25:06.128211Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier_gs = GridSearchCV(tree_pipeline, param_grid, \n",
    "                             scoring=\"recall\", cv=k_fold, \n",
    "                             n_jobs=-1, verbose=1)\n",
    "\n",
    "classifier_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:31:32.154973Z",
     "start_time": "2020-01-28T16:31:32.116211Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Best parameters: {classifier_gs.best_params_}\") \n",
    "print(f\"Recall (Training set): {classifier_gs.best_score_:.4f}\") \n",
    "print(f\"Recall (Test set): {metrics.recall_score(y_test, classifier_gs.predict(X_test)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Evaluate the performance of the tuned pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:31:42.049117Z",
     "start_time": "2020-01-28T16:31:32.317422Z"
    }
   },
   "outputs": [],
   "source": [
    "LABELS = [\"No Default\", \"Default\"]\n",
    "tree_gs_perf = performance_evaluation_report(classifier_gs, X_test, \n",
    "                                             y_test, labels=LABELS, \n",
    "                                             show_plot=True)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_13_26\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:31:42.240641Z",
     "start_time": "2020-01-28T16:31:42.236741Z"
    }
   },
   "outputs": [],
   "source": [
    "tree_gs_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Run the randomized grid search: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:33:55.367212Z",
     "start_time": "2020-01-28T16:31:42.420281Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier_rs = RandomizedSearchCV(tree_pipeline, param_grid, \n",
    "                                   scoring=\"recall\", cv=k_fold, \n",
    "                                   n_jobs=-1, verbose=1, \n",
    "                                   n_iter=100, random_state=42)\n",
    "classifier_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:33:55.661198Z",
     "start_time": "2020-01-28T16:33:55.613345Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Best parameters: {classifier_rs.best_params_}\") \n",
    "print(f\"Recall (Training set): {classifier_rs.best_score_:.4f}\") \n",
    "print(f\"Recall (Test set): {metrics.recall_score(y_test, classifier_rs.predict(X_test)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T10:18:12.199092Z",
     "start_time": "2019-11-13T10:18:12.195250Z"
    }
   },
   "source": [
    "9. Evaluate the performance of the Randomized Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:34:05.588141Z",
     "start_time": "2020-01-28T16:33:55.905898Z"
    }
   },
   "outputs": [],
   "source": [
    "tree_rs_perf = performance_evaluation_report(classifier_rs, X_test, \n",
    "                                             y_test, labels=LABELS, \n",
    "                                             show_plot=True)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:34:05.808345Z",
     "start_time": "2020-01-28T16:34:05.804213Z"
    }
   },
   "outputs": [],
   "source": [
    "tree_rs_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faster search with successive halving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "# using the default values for min_resources and factor\n",
    "classifier_sh = HalvingGridSearchCV(tree_pipeline, param_grid, \n",
    "                                    scoring=\"recall\", cv=k_fold, \n",
    "                                    n_jobs=-1, verbose=1, \n",
    "                                    min_resources=\"exhaust\", factor=3)\n",
    "\n",
    "classifier_sh.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters: {classifier_sh.best_params_}\") \n",
    "print(f\"Recall (Training set): {classifier_sh.best_score_:.4f}\") \n",
    "print(f\"Recall (Test set): {metrics.recall_score(y_test, classifier_sh.predict(X_test)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_sh_perf = performance_evaluation_report(classifier_sh, X_test, \n",
    "                                             y_test, labels=LABELS, \n",
    "                                             show_plot=True)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data = [\n",
    "        classifier_gs.best_params_, \n",
    "        classifier_rs.best_params_, \n",
    "        classifier_sh.best_params_\n",
    "    ],\n",
    "    index = [\"grid_search\", \"randomized_search\", \"halving_search\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data = [tree_gs_perf, tree_rs_perf, tree_sh_perf],\n",
    "    index = [\"grid_search\", \"randomized_search\", \"halving_search\"]\n",
    ").round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search with multiple classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:34:06.058726Z",
     "start_time": "2020-01-28T16:34:06.055964Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:34:06.294868Z",
     "start_time": "2020-01-28T16:34:06.290799Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"classifier\": [RandomForestClassifier(random_state=42)],\n",
    "     \"classifier__n_estimators\": np.linspace(100, 500, 10, dtype=int),\n",
    "     \"classifier__max_depth\": range(3, 11),\n",
    "     \"preprocessor__numerical__outliers__n_std\": [3, 4]},\n",
    "    {\"classifier\": [DecisionTreeClassifier(random_state=42)],\n",
    "     \"classifier__criterion\": [\"entropy\", \"gini\"],\n",
    "     \"classifier__max_depth\": range(3, 11),\n",
    "     \"classifier__min_samples_leaf\": range(2, 11),\n",
    "     \"preprocessor__numerical__outliers__n_std\": [3, 4]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T16:41:34.895345Z",
     "start_time": "2020-01-28T16:34:06.518726Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier_gs_2 = GridSearchCV(tree_pipeline, param_grid, \n",
    "                               scoring=\"recall\", cv=k_fold, \n",
    "                               n_jobs=-1, verbose=1)\n",
    "\n",
    "classifier_gs_2.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {classifier_gs_2.best_params_}\") \n",
    "print(f\"Recall (Training set): {classifier_gs_2.best_score_:.4f}\") \n",
    "print(f\"Recall (Test set): {metrics.recall_score(y_test, classifier_gs_2.predict(X_test)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classifier_gs_2.cv_results_).sort_values(\"rank_test_score\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0117835dafdb051235b33d006a7ad155411608685e1d44af6fb551f6db3e7774"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "268px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
