{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:24:54.871706Z",
     "start_time": "2020-01-29T15:24:54.859745Z"
    }
   },
   "source": [
    "Please run those two cells before running the Notebook!\n",
    "\n",
    "As those plotting settings are standard throughout the book, we do not show them in the book every time we plot something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T15:24:55.068103Z",
     "start_time": "2020-01-29T15:24:55.064292Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "# FIX: Use the official public API path from pandas.errors\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "# feel free to modify, for example, change the context to \"notebook\"\n",
    "sns.set_theme(context=\"talk\", style=\"whitegrid\", \n",
    "              palette=\"colorblind\", color_codes=True, \n",
    "              rc={\"figure.figsize\": [12, 8]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9 - Modeling Volatility with GARCH class models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Modeling stock returns' volatility with ARCH models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: Install the arch library for volatility modeling\n",
    "!pip install arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T21:09:20.396883Z",
     "start_time": "2020-01-19T21:09:20.393875Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Specify the risky asset and the time horizon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T21:09:21.344708Z",
     "start_time": "2020-01-19T21:09:21.341934Z"
    }
   },
   "outputs": [],
   "source": [
    "RISKY_ASSET = \"GOOG\"\n",
    "START_DATE = \"2015-01-01\"\n",
    "END_DATE = \"2021-12-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Download data from Yahoo Finance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T21:09:22.304308Z",
     "start_time": "2020-01-19T21:09:21.970298Z"
    }
   },
   "outputs": [],
   "source": [
    "df = yf.download(RISKY_ASSET,\n",
    "                 start=START_DATE,\n",
    "                 end=END_DATE,\n",
    "                 auto_adjust=True) # FIX: Replaced 'adjusted' with 'auto_adjust'\n",
    "\n",
    "print(f\"Downloaded {df.shape[0]} rows of data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calculate daily returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T21:10:07.637791Z",
     "start_time": "2020-01-19T21:09:50.169941Z"
    }
   },
   "outputs": [],
   "source": [
    "returns = 100 * df[\"Adj Close\"].pct_change().dropna()\n",
    "returns.name = \"asset_returns\"\n",
    "print(f\"Average return: {round(returns.mean(), 2)}%\")\n",
    "returns.plot(title=f\"{RISKY_ASSET} returns: {START_DATE} - {END_DATE}\");\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_9_1\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Specify the ARCH model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T21:10:24.999578Z",
     "start_time": "2020-01-19T21:10:24.994614Z"
    }
   },
   "outputs": [],
   "source": [
    "model = arch_model(returns, mean=\"Zero\", vol=\"ARCH\", p=1, q=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Estimate the model and print the summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T21:10:26.825017Z",
     "start_time": "2020-01-19T21:10:26.798525Z"
    }
   },
   "outputs": [],
   "source": [
    "fitted_model = model.fit(disp=\"off\")\n",
    "print(fitted_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Plot the residuals and the conditional volatility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T21:12:26.607180Z",
     "start_time": "2020-01-19T21:12:07.837341Z"
    }
   },
   "outputs": [],
   "source": [
    "fitted_model.plot(annualize=\"D\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_9_2\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we confirm that the standardized residuals are simply residuals divided by the conditional volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics_dict = {\n",
    "    \"resids\": fitted_model.resid,\n",
    "    \"conditional_volatility\": fitted_model.conditional_volatility,\n",
    "    \"std_resid\": fitted_model.std_resid,\n",
    "    \"std_resid_manual\": fitted_model.resid / fitted_model.conditional_volatility,\n",
    "}\n",
    "\n",
    "df_diagnostics = pd.DataFrame(data = diagnostics_dict)\n",
    "df_diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the residuals of the ARCH(1) model with the LM test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_arch\n",
    "het_arch(fitted_model.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the residuals come from a model in which we estimated two parameters (omega and alpha), we should correct for that when using the `het_arch` test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_arch(fitted_model.resid, ddof=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Modeling stock returns' volatility with GARCH models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Specify the GARCH model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T21:45:10.778892Z",
     "start_time": "2020-01-19T21:45:10.774642Z"
    }
   },
   "outputs": [],
   "source": [
    "model = arch_model(returns, mean=\"Zero\", vol=\"GARCH\", p=1, q=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Estimate the model and print the summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T21:45:11.750954Z",
     "start_time": "2020-01-19T21:45:11.722528Z"
    }
   },
   "outputs": [],
   "source": [
    "fitted_model = model.fit(disp=\"off\")\n",
    "print(fitted_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Plot the residuals and the conditional volatility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T21:46:00.773511Z",
     "start_time": "2020-01-19T21:45:42.976858Z"
    }
   },
   "outputs": [],
   "source": [
    "fitted_model.plot(annualize=\"D\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_9_3\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Forecasting volatility using GARCH models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T21:09:20.396883Z",
     "start_time": "2020-01-19T21:09:20.393875Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download data from Yahoo Finance and calculate simple returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T21:09:22.304308Z",
     "start_time": "2020-01-19T21:09:21.970298Z"
    }
   },
   "outputs": [],
   "source": [
    "df = yf.download(\"MSFT\",\n",
    "                 start=\"2015-01-01\",\n",
    "                 end=\"2021-12-31\",\n",
    "                 adjusted=True)\n",
    "\n",
    "returns = 100 * df[\"Adj Close\"].pct_change().dropna()\n",
    "returns.name = \"asset_returns\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Specify the GARCH model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = arch_model(returns, mean=\"Zero\", vol=\"GARCH\", dist=\"t\",\n",
    "                   p=1, q=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define the split date and fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_DATE = datetime(2021, 1, 1)\n",
    "fitted_model = model.fit(last_obs=SPLIT_DATE, disp=\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create and inspect the analytical forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_analytical = fitted_model.forecast(horizon=3, \n",
    "                                             start=SPLIT_DATE,\n",
    "                                             reindex=False)\n",
    "forecasts_analytical.variance.plot(\n",
    "    title=\"Analytical forecasts for different horizons\"\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_9_4\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_analytical.variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create and inspect the simulation forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_simulation = fitted_model.forecast(horizon=3, \n",
    "                                             start=SPLIT_DATE,\n",
    "                                             method=\"simulation\",\n",
    "                                             reindex=False)\n",
    "forecasts_simulation.variance.plot(\n",
    "    title=\"Simulation forecasts for different horizons\"\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_9_6\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_simulation.variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Create and inspect the bootstrap forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_bootstrap = fitted_model.forecast(horizon=3, \n",
    "                                            start=SPLIT_DATE,\n",
    "                                            method=\"bootstrap\",\n",
    "                                            reindex=False)\n",
    "forecasts_bootstrap.variance.plot(\n",
    "    title=\"Bootstrap forecasts for different horizons\"\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_9_7\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_bootstrap.variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Estimate the volatility forecasts for 2020 using the analytic and bootstrap approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the forecast horizon\n",
    "FCST_HORIZON = 10\n",
    "\n",
    "vol_analytic = (\n",
    "    fitted_model.forecast(horizon=FCST_HORIZON, \n",
    "                          start=datetime(2020, 1, 1),\n",
    "                          reindex=False)\n",
    "    .residual_variance[\"2020\"]\n",
    "    .apply(np.sqrt)\n",
    ")\n",
    "\n",
    "vol_bootstrap = (\n",
    "    fitted_model.forecast(horizon=FCST_HORIZON, \n",
    "                          start=datetime(2020, 1, 1),\n",
    "                          method=\"bootstrap\",\n",
    "                          reindex=False)\n",
    "    .residual_variance[\"2020\"]\n",
    "    .apply(np.sqrt)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Get the conditional volatility for 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = fitted_model.conditional_volatility[\"2020\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create the hedgehog plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = vol.plot(\n",
    "    title=\"Comparison of analytical vs bootstrap volatility forecasts\",\n",
    "    alpha=0.5\n",
    ")\n",
    "ind = vol.index\n",
    "\n",
    "for i in range(0, 240, 10):\n",
    "    vol_a = vol_analytic.iloc[i]\n",
    "    vol_b = vol_bootstrap.iloc[i]\n",
    "    start_loc = ind.get_loc(vol_a.name)\n",
    "    new_ind = ind[(start_loc+1):(start_loc+FCST_HORIZON+1)]\n",
    "    vol_a.index = new_ind\n",
    "    vol_b.index = new_ind\n",
    "    ax.plot(vol_a, color=\"r\")\n",
    "    ax.plot(vol_b, color=\"g\")\n",
    "\n",
    "labels = [\"Volatility\", \"Analytical Forecast\", \"Bootstrap Forecast\"]\n",
    "legend = ax.legend(labels)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_9_8\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Multivariate volatility forecasting with the CCC-GARCH model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:40:36.309976Z",
     "start_time": "2020-01-28T10:40:33.603973Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Specify the risky asset and the time horizon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:40:36.330886Z",
     "start_time": "2020-01-28T10:40:36.327212Z"
    }
   },
   "outputs": [],
   "source": [
    "RISKY_ASSETS = [\"GOOG\", \"MSFT\", \"AAPL\"]\n",
    "START_DATE = \"2015-01-01\"\n",
    "END_DATE = \"2021-12-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Download data from Yahoo Finance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:40:37.048832Z",
     "start_time": "2020-01-28T10:40:36.344978Z"
    }
   },
   "outputs": [],
   "source": [
    "df = yf.download(RISKY_ASSETS,\n",
    "                 start=START_DATE,\n",
    "                 end=END_DATE,\n",
    "                 adjusted=True)\n",
    "\n",
    "print(f\"Downloaded {df.shape[0]} rows of data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calculate daily returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:40:53.029394Z",
     "start_time": "2020-01-28T10:40:37.091386Z"
    }
   },
   "outputs": [],
   "source": [
    "returns = 100 * df[\"Adj Close\"].pct_change().dropna()\n",
    "returns.plot(subplots=True, \n",
    "             title=f\"Stock returns: {START_DATE} - {END_DATE}\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/figure_9_9\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define lists for storing objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:40:53.074592Z",
     "start_time": "2020-01-28T10:40:53.072235Z"
    }
   },
   "outputs": [],
   "source": [
    "coeffs = []\n",
    "cond_vol = []\n",
    "std_resids = []\n",
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Estimate the univariate GARCH models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:40:53.184833Z",
     "start_time": "2020-01-28T10:40:53.116229Z"
    }
   },
   "outputs": [],
   "source": [
    "for asset in returns.columns:\n",
    "    # specify and fit the model\n",
    "    model = arch_model(returns[asset], mean=\"Constant\", \n",
    "                       vol=\"GARCH\", p=1, q=1)\n",
    "    model = model.fit(update_freq=0, disp=\"off\");\n",
    "    \n",
    "    # store results in the lists \n",
    "    coeffs.append(model.params)\n",
    "    cond_vol.append(model.conditional_volatility)\n",
    "    std_resids.append(model.std_resid)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Store the results in DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:40:53.385362Z",
     "start_time": "2020-01-28T10:40:53.311370Z"
    }
   },
   "outputs": [],
   "source": [
    "coeffs_df = pd.DataFrame(coeffs, index=returns.columns)\n",
    "cond_vol_df = (\n",
    "    pd.DataFrame(cond_vol)\n",
    "    .transpose()\n",
    "    .set_axis(returns.columns,\n",
    "              axis=\"columns\")\n",
    ")\n",
    "std_resids_df = (\n",
    "    pd.DataFrame(std_resids)\n",
    "    .transpose()\n",
    "    .set_axis(returns.columns, \n",
    "              axis=\"columns\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:40:53.521651Z",
     "start_time": "2020-01-28T10:40:53.507669Z"
    }
   },
   "outputs": [],
   "source": [
    "coeffs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Calculate the constant conditional correlation matrix (R):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:40:53.646848Z",
     "start_time": "2020-01-28T10:40:53.641441Z"
    }
   },
   "outputs": [],
   "source": [
    "R = (\n",
    "    std_resids_df\n",
    "    .transpose()\n",
    "    .dot(std_resids_df)\n",
    "    .div(len(std_resids_df))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Calculate the 1-step ahead forecast of the conditional covariance matrix :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:40:55.462942Z",
     "start_time": "2020-01-28T10:40:55.452967Z"
    }
   },
   "outputs": [],
   "source": [
    "# define objects\n",
    "diag = []\n",
    "D = np.zeros((len(RISKY_ASSETS), len(RISKY_ASSETS)))\n",
    "\n",
    "# populate the list with conditional variances\n",
    "for model in models:\n",
    "    diag.append(model.forecast(horizon=1).variance.iloc[-1, 0])\n",
    "# take the square root to obtain volatility from variance\n",
    "diag = np.sqrt(diag)\n",
    "# fill the diagonal of D with values from diag\n",
    "np.fill_diagonal(D, diag)\n",
    "\n",
    "# calculate the conditional covariance matrix\n",
    "H = np.matmul(np.matmul(D, R.values), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:40:56.242379Z",
     "start_time": "2020-01-28T10:40:56.238321Z"
    }
   },
   "outputs": [],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 Forecasting the conditional covariance matrix using DCC-GARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before executing the following code, please make sure to run the code from the previous recipe to have the data available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:41:09.595417Z",
     "start_time": "2020-01-28T10:41:09.592618Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the connection between Python and R using `rpy2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:41:10.603867Z",
     "start_time": "2020-01-28T10:41:09.954390Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Install `rmgarch` R package and load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:41:13.077879Z",
     "start_time": "2020-01-28T10:41:11.315555Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "install.packages(\"rmgarch\", repos = \"http://cran.us.r-project.org\")\n",
    "library(rmgarch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Import the dataset into R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:41:18.706237Z",
     "start_time": "2020-01-28T10:41:18.649143Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R -i returns\n",
    "print(head(returns, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define the model specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T10:45:04.420308Z",
     "start_time": "2020-01-28T10:45:03.810189Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# define GARCH(1,1) model\n",
    "univariate_spec <- ugarchspec(\n",
    "    mean.model = list(armaOrder = c(0,0)),\n",
    "    variance.model = list(garchOrder = c(1,1), \n",
    "                          model = \"sGARCH\"),\n",
    "    distribution.model = \"norm\"\n",
    ")\n",
    "\n",
    "# define DCC(1,1) model\n",
    "n <- dim(returns)[2]\n",
    "dcc_spec <- dccspec(\n",
    "    uspec = multispec(replicate(n, univariate_spec)),\n",
    "    dccOrder = c(1,1),\n",
    "    distribution = \"mvnorm\"\n",
    ")\n",
    "\n",
    "dcc_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Estimate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-01T19:53:16.491Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "dcc_fit <- dccfit(dcc_spec, data=returns)\n",
    "dcc_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Calculate the 5-step ahead forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "forecasts <- dccforecast(dcc_fit, n.ahead = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Access the forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# conditional covariance matrix\n",
    "forecasts@mforecast$H\n",
    "# conditional correlation matrix\n",
    "forecasts@mforecast$R\n",
    "# proxy correlation process\n",
    "forecasts@mforecast$Q\n",
    "# conditional mean forecasts\n",
    "forecasts@mforecast$mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# parallelized DCC-GARCH(1,1)\n",
    "\n",
    "library(\"parallel\")\n",
    "\n",
    "# set up the cluster\n",
    "cl <- makePSOCKcluster(3)\n",
    "\n",
    "# define parallelizable specification\n",
    "parallel_fit <- multifit(multispec(replicate(n, univariate_spec)), \n",
    "                         returns, \n",
    "                         cluster = cl)\n",
    "\n",
    "# fit the DCC-GARCH model\n",
    "dcc_fit <- dccfit(dcc_spec, \n",
    "                  data = returns, \n",
    "                  fit.control = list(eval.se = TRUE), \n",
    "                  fit = parallel_fit, \n",
    "                  cluster = cl)\n",
    "\n",
    "# stop the cluster\n",
    "stopCluster(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "dcc_fit"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0117835dafdb051235b33d006a7ad155411608685e1d44af6fb551f6db3e7774"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
