{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OEACZptdHC7"
   },
   "source": [
    "Please run those two cells before running the Notebook!\n",
    "\n",
    "As those plotting settings are standard throughout the book, we do not show them in the book every time we plot something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:48:06.120195Z",
     "start_time": "2020-01-29T10:48:05.814125Z"
    },
    "id": "_JscbREmdHC-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:48:13.141309Z",
     "start_time": "2020-01-29T10:48:13.137453Z"
    },
    "id": "r6OEEsWTdHDB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "# FIX: Use the official public API path from pandas.errors\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "# feel free to modify, for example, change the context to \"notebook\"\n",
    "sns.set_theme(context=\"talk\", style=\"whitegrid\", \n",
    "              palette=\"colorblind\", color_codes=True, \n",
    "              rc={\"figure.figsize\": [12, 8]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 - ML-based Approaches to Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Validation methods for time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import nasdaqdatalink\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YK5hwjxe3Swf2y_zTjxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the monthly US unemployment rate from years 2010-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-datareader in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas-datareader) (5.3.0)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas-datareader) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas-datareader) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.23->pandas-datareader) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "# FIX: Install the pandas-datareader library\n",
    "!pip install pandas-datareader\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# FIX: Download the data directly from FRED using its series ID \"UNRATENSA\"\n",
    "df = (\n",
    "    web.DataReader(name=\"UNRATENSA\", \n",
    "                   data_source=\"fred\",\n",
    "                   start=\"2010-01-01\",\n",
    "                   end=\"2019-12-31\")\n",
    "    .rename(columns={\"UNRATENSA\": \"unemp_rate\"})\n",
    ")\n",
    "\n",
    "df.plot(title=\"Unemployment rate (US) - monthly\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create simple features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unemp_rate</th>\n",
       "      <th>linear_trend</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>10.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-01</th>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01</th>\n",
       "      <td>10.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-01</th>\n",
       "      <td>9.5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-01</th>\n",
       "      <td>9.3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>3.8</td>\n",
       "      <td>115</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>3.3</td>\n",
       "      <td>116</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>3.3</td>\n",
       "      <td>117</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>3.3</td>\n",
       "      <td>118</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>3.4</td>\n",
       "      <td>119</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            unemp_rate  linear_trend  month\n",
       "DATE                                       \n",
       "2010-01-01        10.6             0      1\n",
       "2010-02-01        10.4             1      2\n",
       "2010-03-01        10.2             2      3\n",
       "2010-04-01         9.5             3      4\n",
       "2010-05-01         9.3             4      5\n",
       "...                ...           ...    ...\n",
       "2019-08-01         3.8           115      8\n",
       "2019-09-01         3.3           116      9\n",
       "2019-10-01         3.3           117     10\n",
       "2019-11-01         3.3           118     11\n",
       "2019-12-01         3.4           119     12\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"linear_trend\"] = range(len(df))\n",
    "df[\"month\"] = df.index.month\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use one-hot encoding for the month feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unemp_rate</th>\n",
       "      <th>linear_trend</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>10.6</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-01</th>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01</th>\n",
       "      <td>10.2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-01</th>\n",
       "      <td>9.5</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-01</th>\n",
       "      <td>9.3</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>3.8</td>\n",
       "      <td>115</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>3.3</td>\n",
       "      <td>116</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>3.3</td>\n",
       "      <td>117</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>3.3</td>\n",
       "      <td>118</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>3.4</td>\n",
       "      <td>119</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            unemp_rate  linear_trend  month_2  month_3  month_4  month_5  \\\n",
       "DATE                                                                       \n",
       "2010-01-01        10.6             0    False    False    False    False   \n",
       "2010-02-01        10.4             1     True    False    False    False   \n",
       "2010-03-01        10.2             2    False     True    False    False   \n",
       "2010-04-01         9.5             3    False    False     True    False   \n",
       "2010-05-01         9.3             4    False    False    False     True   \n",
       "...                ...           ...      ...      ...      ...      ...   \n",
       "2019-08-01         3.8           115    False    False    False    False   \n",
       "2019-09-01         3.3           116    False    False    False    False   \n",
       "2019-10-01         3.3           117    False    False    False    False   \n",
       "2019-11-01         3.3           118    False    False    False    False   \n",
       "2019-12-01         3.4           119    False    False    False    False   \n",
       "\n",
       "            month_6  month_7  month_8  month_9  month_10  month_11  month_12  \n",
       "DATE                                                                          \n",
       "2010-01-01    False    False    False    False     False     False     False  \n",
       "2010-02-01    False    False    False    False     False     False     False  \n",
       "2010-03-01    False    False    False    False     False     False     False  \n",
       "2010-04-01    False    False    False    False     False     False     False  \n",
       "2010-05-01    False    False    False    False     False     False     False  \n",
       "...             ...      ...      ...      ...       ...       ...       ...  \n",
       "2019-08-01    False    False     True    False     False     False     False  \n",
       "2019-09-01    False    False    False     True     False     False     False  \n",
       "2019-10-01    False    False    False    False      True     False     False  \n",
       "2019-11-01    False    False    False    False     False      True     False  \n",
       "2019-12-01    False    False    False    False     False     False      True  \n",
       "\n",
       "[120 rows x 13 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_dummies = pd.get_dummies(\n",
    "    df[\"month\"], drop_first=True, prefix=\"month\"\n",
    ")\n",
    "\n",
    "df = df.join(month_dummies) \\\n",
    "       .drop(columns=[\"month\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Separate the target from the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(\"unemp_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 12)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Define the expanding window walk-forward validation and print the indices of the folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 ----\n",
      "Train indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59]\n",
      "Valid indices: [60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "Fold 1 ----\n",
      "Train indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "Valid indices: [72 73 74 75 76 77 78 79 80 81 82 83]\n",
      "Fold 2 ----\n",
      "Train indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83]\n",
      "Valid indices: [84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "Fold 3 ----\n",
      "Train indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "Valid indices: [ 96  97  98  99 100 101 102 103 104 105 106 107]\n",
      "Fold 4 ----\n",
      "Train indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107]\n",
      "Valid indices: [108 109 110 111 112 113 114 115 116 117 118 119]\n"
     ]
    }
   ],
   "source": [
    "expanding_cv = TimeSeriesSplit(n_splits=5, test_size=12)\n",
    "\n",
    "for fold, (train_ind, valid_ind) in enumerate(expanding_cv.split(X)):\n",
    "    print(f\"Fold {fold} ----\")\n",
    "    print(f\"Train indices: {train_ind}\")\n",
    "    print(f\"Valid indices: {valid_ind}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Evaluate the model's performance using the expanding window validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.03705079312389471, 0.07828415627306329, 0.11981060282172923, 0.1682949401291087, 0.25460459651634143]\n",
      "Avg. score: 0.13160901777282746\n"
     ]
    }
   ],
   "source": [
    "scores = [] \n",
    "\n",
    "for train_ind, valid_ind in expanding_cv.split(X):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X.iloc[train_ind], y.iloc[train_ind])\n",
    "    y_pred = lr.predict(X.iloc[valid_ind])\n",
    "    scores.append(\n",
    "        mean_absolute_percentage_error(y.iloc[valid_ind], y_pred)\n",
    "    )\n",
    "\n",
    "print(f\"Scores: {scores}\")\n",
    "print(f\"Avg. score: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012541</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>-0.037051</td>\n",
       "      <td>-0.232500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>-0.078284</td>\n",
       "      <td>-0.433547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004022</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>-0.119811</td>\n",
       "      <td>-0.520073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008637</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>-0.168295</td>\n",
       "      <td>-0.662540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.254605</td>\n",
       "      <td>-0.928998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_absolute_percentage_error  \\\n",
       "0  0.012541    0.003760                                -0.037051   \n",
       "1  0.000000    0.012201                                -0.078284   \n",
       "2  0.004022    0.001973                                -0.119811   \n",
       "3  0.008637    0.003703                                -0.168295   \n",
       "4  0.000000    0.000000                                -0.254605   \n",
       "\n",
       "   test_neg_root_mean_squared_error  \n",
       "0                         -0.232500  \n",
       "1                         -0.433547  \n",
       "2                         -0.520073  \n",
       "3                         -0.662540  \n",
       "4                         -0.928998  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores = cross_validate(\n",
    "    LinearRegression(), \n",
    "    X, y, \n",
    "    cv=expanding_cv, \n",
    "    scoring=[\"neg_mean_absolute_percentage_error\", \n",
    "             \"neg_root_mean_squared_error\"]\n",
    ")\n",
    "pd.DataFrame(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Define the sliding window validation and print the indices of the folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 ----\n",
      "Train indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59]\n",
      "Valid indices: [60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "Fold 1 ----\n",
      "Train indices: [12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35\n",
      " 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59\n",
      " 60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "Valid indices: [72 73 74 75 76 77 78 79 80 81 82 83]\n",
      "Fold 2 ----\n",
      "Train indices: [24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83]\n",
      "Valid indices: [84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "Fold 3 ----\n",
      "Train indices: [36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59\n",
      " 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "Valid indices: [ 96  97  98  99 100 101 102 103 104 105 106 107]\n",
      "Fold 4 ----\n",
      "Train indices: [ 48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107]\n",
      "Valid indices: [108 109 110 111 112 113 114 115 116 117 118 119]\n"
     ]
    }
   ],
   "source": [
    "sliding_cv = TimeSeriesSplit(\n",
    "    n_splits=5, test_size=12, max_train_size=60\n",
    ")\n",
    "\n",
    "for fold, (train_ind, valid_ind) in enumerate(sliding_cv.split(X)):\n",
    "    print(f\"Fold {fold} ----\")\n",
    "    print(f\"Train indices: {train_ind}\")\n",
    "    print(f\"Valid indices: {valid_ind}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Evaluate the model's performance using the sliding window validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006811</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>-0.037051</td>\n",
       "      <td>-0.232500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>-0.097125</td>\n",
       "      <td>-0.524333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>-0.126609</td>\n",
       "      <td>-0.550749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>-0.129454</td>\n",
       "      <td>-0.518194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>-0.108759</td>\n",
       "      <td>-0.407428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_absolute_percentage_error  \\\n",
       "0  0.006811    0.001506                                -0.037051   \n",
       "1  0.008571    0.004574                                -0.097125   \n",
       "2  0.001228    0.009143                                -0.126609   \n",
       "3  0.004823    0.001845                                -0.129454   \n",
       "4  0.000000    0.011729                                -0.108759   \n",
       "\n",
       "   test_neg_root_mean_squared_error  \n",
       "0                         -0.232500  \n",
       "1                         -0.524333  \n",
       "2                         -0.550749  \n",
       "3                         -0.518194  \n",
       "4                         -0.407428  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores = cross_validate(\n",
    "    LinearRegression(), \n",
    "    X, y, \n",
    "    cv=sliding_cv, \n",
    "    scoring=[\"neg_mean_absolute_percentage_error\", \n",
    "             \"neg_root_mean_squared_error\"]\n",
    ")\n",
    "pd.DataFrame(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.09979962624891392)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 * cv_scores[\"test_neg_mean_absolute_percentage_error\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Feature engineering for time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-lego in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.9.5)\n",
      "Requirement already satisfied: narwhals>=1.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-lego) (1.31.0)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-lego) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-lego) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat>=0.1.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-lego) (0.1.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->scikit-lego) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->scikit-lego) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->scikit-lego) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->scikit-lego) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->scikit-lego) (1.16.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->scikit-lego) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->scikit-lego) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->scikit-lego) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "# FIX: Install the scikit-lego library\n",
    "!pip install scikit-lego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklego.preprocessing import RepeatingBasisFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary change for this recipe\n",
    "sns.set_palette([\"grey\", \"blue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generate a time series with repeating patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "range_of_dates = pd.date_range(start=\"2017-01-01\", \n",
    "                               end=\"2019-12-31\")\n",
    "X = pd.DataFrame(index=range_of_dates)\n",
    "\n",
    "X[\"day_nr\"] = range(len(X))\n",
    "X[\"day_of_year\"] = X.index.day_of_year\n",
    "\n",
    "signal_1 = 2 + 3 * np.sin(X[\"day_nr\"] / 365 * 2 * np.pi)\n",
    "signal_2 = 2 * np.sin(X[\"day_nr\"] / 365 * 4 * np.pi + 365/2)\n",
    "noise = np.random.normal(0, 0.81, len(X))\n",
    "\n",
    "y = signal_1 + signal_2 + noise\n",
    "y.name = \"y\"\n",
    "\n",
    "y.plot(title=\"Generated time series\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_nr</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>1090</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>1091</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>1092</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>1093</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>1094</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1095 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            day_nr  day_of_year\n",
       "2017-01-01       0            1\n",
       "2017-01-02       1            2\n",
       "2017-01-03       2            3\n",
       "2017-01-04       3            4\n",
       "2017-01-05       4            5\n",
       "...            ...          ...\n",
       "2019-12-27    1090          361\n",
       "2019-12-28    1091          362\n",
       "2019-12-29    1092          363\n",
       "2019-12-30    1093          364\n",
       "2019-12-31    1094          365\n",
       "\n",
       "[1095 rows x 2 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Store the time series in a new DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>2.969692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>2.572678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>3.325853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>4.150575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>2.842004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              y_true\n",
       "2017-01-01  2.969692\n",
       "2017-01-02  2.572678\n",
       "2017-01-03  3.325853\n",
       "2017-01-04  4.150575\n",
       "2017-01-05  2.842004"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = y.to_frame()\n",
    "results_df.columns = [\"y_true\"]\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Encode the month information as dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1095 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            month_2  month_3  month_4  month_5  month_6  month_7  month_8  \\\n",
       "2017-01-01    False    False    False    False    False    False    False   \n",
       "2017-01-02    False    False    False    False    False    False    False   \n",
       "2017-01-03    False    False    False    False    False    False    False   \n",
       "2017-01-04    False    False    False    False    False    False    False   \n",
       "2017-01-05    False    False    False    False    False    False    False   \n",
       "...             ...      ...      ...      ...      ...      ...      ...   \n",
       "2019-12-27    False    False    False    False    False    False    False   \n",
       "2019-12-28    False    False    False    False    False    False    False   \n",
       "2019-12-29    False    False    False    False    False    False    False   \n",
       "2019-12-30    False    False    False    False    False    False    False   \n",
       "2019-12-31    False    False    False    False    False    False    False   \n",
       "\n",
       "            month_9  month_10  month_11  month_12  \n",
       "2017-01-01    False     False     False     False  \n",
       "2017-01-02    False     False     False     False  \n",
       "2017-01-03    False     False     False     False  \n",
       "2017-01-04    False     False     False     False  \n",
       "2017-01-05    False     False     False     False  \n",
       "...             ...       ...       ...       ...  \n",
       "2019-12-27    False     False     False      True  \n",
       "2019-12-28    False     False     False      True  \n",
       "2019-12-29    False     False     False      True  \n",
       "2019-12-30    False     False     False      True  \n",
       "2019-12-31    False     False     False      True  \n",
       "\n",
       "[1095 rows x 11 columns]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = pd.get_dummies(\n",
    "    X.index.month, drop_first=True, prefix=\"month\"\n",
    ")\n",
    "X_1.index = X.index\n",
    "X_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fit a linear regression model and plot the in-sample prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LinearRegression().fit(X_1, y)\n",
    "\n",
    "results_df[\"y_pred_1\"] = model_1.predict(X_1)\n",
    "(\n",
    "    results_df[[\"y_true\", \"y_pred_1\"]]\n",
    "    .plot(title=\"Fit using month dummies\")\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Define functions used for creating the cyclical encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_transformer(period):\n",
    "\treturn FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "\n",
    "def cos_transformer(period):\n",
    "\treturn FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Encode the month and day information using cyclical encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X.copy()\n",
    "X_2[\"month\"] = X_2.index.month\n",
    "\n",
    "X_2[\"month_sin\"] = sin_transformer(12).fit_transform(X_2)[\"month\"]\n",
    "X_2[\"month_cos\"] = cos_transformer(12).fit_transform(X_2)[\"month\"]\n",
    "\n",
    "X_2[\"day_sin\"] = (\n",
    "    sin_transformer(365).fit_transform(X_2)[\"day_of_year\"]\n",
    ")\n",
    "X_2[\"day_cos\"] = (\n",
    "    cos_transformer(365).fit_transform(X_2)[\"day_of_year\"]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, sharex=True, figsize=(16,8))\n",
    "X_2[[\"month_sin\", \"month_cos\"]].plot(ax=ax[0])\n",
    "ax[0].legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "X_2[[\"day_sin\", \"day_cos\"]].plot(ax=ax[1])\n",
    "ax[1].legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.suptitle(\"Cyclical encoding with sine/cosine transformation\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_2[X_2.index.year == 2017]\n",
    "    .plot(\n",
    "        kind=\"scatter\", \n",
    "        x=\"month_sin\", \n",
    "        y=\"month_cos\", \n",
    "        figsize=(8, 8),\n",
    "        title=\"Cyclical encoding using sine/cosine transformations\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Fit a model using the daily sine/cosine features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_2[[\"day_sin\", \"day_cos\"]]\n",
    "\n",
    "model_2 = LinearRegression().fit(X_2, y)\n",
    "\n",
    "results_df[\"y_pred_2\"] = model_2.predict(X_2)\n",
    "(\n",
    "    results_df[[\"y_true\", \"y_pred_2\"]]\n",
    "    .plot(title=\"Fit using sine/cosine features\")\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Create features using the radial basis functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = RepeatingBasisFunction(n_periods=12,\n",
    "                             column=\"day_of_year\",\n",
    "                             input_range=(1,365),\n",
    "                             remainder=\"drop\")\n",
    "rbf.fit(X)\n",
    "X_3 = pd.DataFrame(index=X.index, \n",
    "                   data=rbf.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3.plot(subplots=True, sharex=True, \n",
    "         title=\"Radial Basis Functions\", \n",
    "         legend=False, figsize=(14, 10))\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Fit a model using the RBF features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = LinearRegression().fit(X_3, y)\n",
    "\n",
    "results_df[\"y_pred_3\"] = model_3.predict(X_3)\n",
    "(\n",
    "    results_df[[\"y_true\", \"y_pred_3\"]]\n",
    "    .plot(title=\"Fit using RBF features\")\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\Lenovo\\\\AppData\\\\Local\\\\Temp\\\\pip-unpack-ann1a4ds\\\\numpy-2.1.3-cp312-cp312-win_amd64.whl'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tsfresh\n",
      "  Downloading tsfresh-0.21.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: requests>=2.9.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tsfresh) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.15.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tsfresh) (2.2.4)\n",
      "Requirement already satisfied: pandas>=0.25.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tsfresh) (2.3.1)\n",
      "Requirement already satisfied: statsmodels>=0.13 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tsfresh) (0.14.4)\n",
      "Requirement already satisfied: patsy>=0.4.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tsfresh) (1.0.1)\n",
      "Requirement already satisfied: pywavelets in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tsfresh) (1.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tsfresh) (1.6.1)\n",
      "Requirement already satisfied: tqdm>=4.10.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tsfresh) (4.67.1)\n",
      "Collecting stumpy>=1.7.2 (from tsfresh)\n",
      "  Downloading stumpy-1.13.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tsfresh) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.14.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tsfresh) (1.15.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.25.0->tsfresh) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.25.0->tsfresh) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.25.0->tsfresh) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.25.0->tsfresh) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.9.1->tsfresh) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.9.1->tsfresh) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.9.1->tsfresh) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.9.1->tsfresh) (2025.7.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.0->tsfresh) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.0->tsfresh) (3.5.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from statsmodels>=0.13->tsfresh) (24.2)\n",
      "Requirement already satisfied: numba>=0.57.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from stumpy>=1.7.2->tsfresh) (0.61.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from numba>=0.57.1->stumpy>=1.7.2->tsfresh) (0.44.0)\n",
      "Collecting numpy>=1.15.1 (from tsfresh)\n",
      "  Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.10.0->tsfresh) (0.4.6)\n",
      "Downloading tsfresh-0.21.0-py2.py3-none-any.whl (96 kB)\n",
      "Downloading stumpy-1.13.0-py3-none-any.whl (176 kB)\n",
      "Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.6 MB 699.0 kB/s eta 0:00:18\n",
      "   - -------------------------------------- 0.5/12.6 MB 699.0 kB/s eta 0:00:18\n",
      "   - -------------------------------------- 0.5/12.6 MB 699.0 kB/s eta 0:00:18\n",
      "   - -------------------------------------- 0.5/12.6 MB 699.0 kB/s eta 0:00:18\n",
      "   -- ------------------------------------- 0.8/12.6 MB 419.4 kB/s eta 0:00:29\n",
      "   -- ------------------------------------- 0.8/12.6 MB 419.4 kB/s eta 0:00:29\n",
      "   -- ------------------------------------- 0.8/12.6 MB 419.4 kB/s eta 0:00:29\n",
      "   -- ------------------------------------- 0.8/12.6 MB 419.4 kB/s eta 0:00:29\n",
      "   -- ------------------------------------- 0.8/12.6 MB 419.4 kB/s eta 0:00:29\n",
      "   --- ------------------------------------ 1.0/12.6 MB 335.7 kB/s eta 0:00:35\n",
      "   --- ------------------------------------ 1.0/12.6 MB 335.7 kB/s eta 0:00:35\n",
      "   --- ------------------------------------ 1.0/12.6 MB 335.7 kB/s eta 0:00:35\n",
      "   --- ------------------------------------ 1.0/12.6 MB 335.7 kB/s eta 0:00:35\n",
      "   --- ------------------------------------ 1.0/12.6 MB 335.7 kB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 302.4 kB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 302.4 kB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 302.4 kB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 302.4 kB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 302.4 kB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 302.4 kB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 302.4 kB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 302.4 kB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 302.4 kB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 302.4 kB/s eta 0:00:38\n",
      "   ----- ---------------------------------- 1.6/12.6 MB 238.3 kB/s eta 0:00:47\n",
      "   ----- ---------------------------------- 1.6/12.6 MB 238.3 kB/s eta 0:00:47\n",
      "   ----- ---------------------------------- 1.6/12.6 MB 238.3 kB/s eta 0:00:47\n",
      "   ----- ---------------------------------- 1.6/12.6 MB 238.3 kB/s eta 0:00:47\n",
      "   ----- ---------------------------------- 1.6/12.6 MB 238.3 kB/s eta 0:00:47\n",
      "   ----- ---------------------------------- 1.6/12.6 MB 238.3 kB/s eta 0:00:47\n",
      "   ----- ---------------------------------- 1.6/12.6 MB 238.3 kB/s eta 0:00:47\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 227.8 kB/s eta 0:00:48\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 227.8 kB/s eta 0:00:48\n",
      "   ------ --------------------------------- 2.1/12.6 MB 246.7 kB/s eta 0:00:43\n",
      "   ------ --------------------------------- 2.1/12.6 MB 246.7 kB/s eta 0:00:43\n",
      "   ------ --------------------------------- 2.1/12.6 MB 246.7 kB/s eta 0:00:43\n",
      "   ------ --------------------------------- 2.1/12.6 MB 246.7 kB/s eta 0:00:43\n",
      "   ------- -------------------------------- 2.4/12.6 MB 258.1 kB/s eta 0:00:40\n",
      "   ------- -------------------------------- 2.4/12.6 MB 258.1 kB/s eta 0:00:40\n",
      "   ------- -------------------------------- 2.4/12.6 MB 258.1 kB/s eta 0:00:40\n",
      "   -------- ------------------------------- 2.6/12.6 MB 266.3 kB/s eta 0:00:38\n",
      "   -------- ------------------------------- 2.6/12.6 MB 266.3 kB/s eta 0:00:38\n",
      "   -------- ------------------------------- 2.6/12.6 MB 266.3 kB/s eta 0:00:38\n",
      "   -------- ------------------------------- 2.6/12.6 MB 266.3 kB/s eta 0:00:38\n",
      "   -------- ------------------------------- 2.6/12.6 MB 266.3 kB/s eta 0:00:38\n",
      "   -------- ------------------------------- 2.6/12.6 MB 266.3 kB/s eta 0:00:38\n",
      "   -------- ------------------------------- 2.6/12.6 MB 266.3 kB/s eta 0:00:38\n",
      "   -------- ------------------------------- 2.6/12.6 MB 266.3 kB/s eta 0:00:38\n",
      "   --------- ------------------------------ 2.9/12.6 MB 250.0 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 2.9/12.6 MB 250.0 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 2.9/12.6 MB 250.0 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 2.9/12.6 MB 250.0 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 2.9/12.6 MB 250.0 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 2.9/12.6 MB 250.0 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 2.9/12.6 MB 250.0 kB/s eta 0:00:39\n",
      "   ---------- ----------------------------- 3.1/12.6 MB 238.7 kB/s eta 0:00:40\n",
      "   ---------- ----------------------------- 3.1/12.6 MB 238.7 kB/s eta 0:00:40\n",
      "   ---------- ----------------------------- 3.1/12.6 MB 238.7 kB/s eta 0:00:40\n",
      "   ---------- ----------------------------- 3.1/12.6 MB 238.7 kB/s eta 0:00:40\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 243.2 kB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 243.2 kB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 243.2 kB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 251.6 kB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 251.6 kB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 251.6 kB/s eta 0:00:36\n",
      "   ------------ --------------------------- 3.9/12.6 MB 259.8 kB/s eta 0:00:34\n",
      "   ------------ --------------------------- 3.9/12.6 MB 259.8 kB/s eta 0:00:34\n",
      "   ------------ --------------------------- 3.9/12.6 MB 259.8 kB/s eta 0:00:34\n",
      "   ------------- -------------------------- 4.2/12.6 MB 267.2 kB/s eta 0:00:32\n",
      "   ------------- -------------------------- 4.2/12.6 MB 267.2 kB/s eta 0:00:32\n",
      "   ------------- -------------------------- 4.2/12.6 MB 267.2 kB/s eta 0:00:32\n",
      "   ------------- -------------------------- 4.2/12.6 MB 267.2 kB/s eta 0:00:32\n",
      "   ------------- -------------------------- 4.2/12.6 MB 267.2 kB/s eta 0:00:32\n",
      "   ------------- -------------------------- 4.2/12.6 MB 267.2 kB/s eta 0:00:32\n",
      "   ------------- -------------------------- 4.2/12.6 MB 267.2 kB/s eta 0:00:32\n",
      "   -------------- ------------------------- 4.4/12.6 MB 257.3 kB/s eta 0:00:32\n"
     ]
    }
   ],
   "source": [
    "# FIX: Install the tsfresh library\n",
    "!pip install tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tsfresh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[457], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DateTimeFeatures\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtsfresh\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_features\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtsfresh\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m settings\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtsfresh\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roll_time_series\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tsfresh'"
     ]
    }
   ],
   "source": [
    "from sktime.transformations.series.date import DateTimeFeatures\n",
    "\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import settings\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extract the datetime-features using `sktime`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_features = DateTimeFeatures(\n",
    "    ts_freq=\"D\", feature_scope=\"comprehensive\"\n",
    ")\n",
    "features_df_1 = dt_features.fit_transform(y)\n",
    "features_df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepare the dataset for feature extraction with `tsfresh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = y.to_frame().reset_index(drop=False)\n",
    "df.columns = [\"date\", \"y\"]\n",
    "df[\"series_id\"] = \"a\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a rolled-up DataFrame for feature extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled = roll_time_series(\n",
    "    df, column_id=\"series_id\", column_sort=\"date\",\n",
    "    max_timeshift=30, min_timeshift=7\n",
    ").drop(columns=[\"series_id\"])\n",
    "df_rolled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Extract the minimal set of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_minimal = settings.MinimalFCParameters() \n",
    "settings_minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df_2 = extract_features(\n",
    "    df_rolled, column_id=\"id\", \n",
    "    column_sort=\"date\", \n",
    "    default_fc_parameters=settings_minimal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Clean up the index and inspect the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df_2 = (\n",
    "    features_df_2\n",
    "    .set_index(\n",
    "        features_df_2.index.map(lambda x: x[1]), drop=True\n",
    "    )\n",
    ")\n",
    "features_df_2.index.name = \"last_date\"\n",
    "features_df_2.head(25).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Time series forecasting as reduced regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nasdaqdatalink\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the monthly US unemployment rate from years 2010-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (\n",
    "    nasdaqdatalink.get(dataset=\"FRED/UNRATENSA\", \n",
    "                       start_date=\"2010-01-01\", \n",
    "                       end_date=\"2019-12-31\")\n",
    "    .rename(columns={\"Value\": \"unemp_rate\"})\n",
    ")\n",
    "y.index = y.index.to_period(freq=\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils.plotting import plot_series\n",
    "from sktime.forecasting.model_selection import (\n",
    "    temporal_train_test_split, ExpandingWindowSplitter\n",
    ")\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.compose import (\n",
    "    make_reduction, TransformedTargetForecaster, \n",
    "    EnsembleForecaster\n",
    ")\n",
    "from sktime.performance_metrics.forecasting import (\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sktime.transformations.series.detrend import (\n",
    "    Deseasonalizer, Detrender\n",
    ")\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.forecasting.model_evaluation import evaluate\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split the time series into training and tests sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = temporal_train_test_split(\n",
    "    y, test_size=12\n",
    ")\n",
    "plot_series(\n",
    "    y_train, y_test, \n",
    "    labels=[\"y_train\", \"y_test\"]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_22\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Set the forecast horizon to 12 months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "fh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Instantiate the reduced regression model, fit it to the data and create predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(random_state=42)\n",
    "rf_forecaster = make_reduction(\n",
    "    estimator=regressor, \n",
    "    strategy=\"recursive\", \n",
    "    window_length=12\n",
    ")\n",
    "rf_forecaster.fit(y_train)\n",
    "y_pred_1 = rf_forecaster.predict(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evaluate the performance of the forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_1 = mean_absolute_percentage_error(\n",
    "    y_test, y_pred_1, symmetric=False\n",
    ")\n",
    "fig, ax = plot_series(\n",
    "    y_train[\"2016\":], y_test, y_pred_1,\n",
    "    labels=[\"y_train\", \"y_test\", \"y_pred\"]\n",
    ")\n",
    "ax.set_title(f\"MAPE: {100*mape_1:.2f}%\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_23\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Deseasonalize the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasonalizer = Deseasonalizer(model=\"additive\", sp=12)\n",
    "y_deseas = deseasonalizer.fit_transform(y_train)\n",
    "plot_series(\n",
    "    y_train, y_deseas, \n",
    "    labels=[\"y_train\", \"y_deseas\"]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(\n",
    "    deseasonalizer.seasonal_, \n",
    "    labels=[\"seasonal_component\"]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Detrend the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = PolynomialTrendForecaster(degree=1)\n",
    "transformer = Detrender(forecaster=forecaster)\n",
    "y_detrend = transformer.fit_transform(y_deseas)\n",
    "\n",
    "# in-sample predictions\n",
    "forecaster = PolynomialTrendForecaster(degree=1)\n",
    "y_in_sample = (\n",
    "    forecaster\n",
    "    .fit(y_deseas)\n",
    "    .predict(fh=-np.arange(len(y_deseas)))\n",
    ")\n",
    "\n",
    "plot_series(\n",
    "    y_deseas, y_in_sample, y_detrend, \n",
    "    labels=[\"y_deseas\", \"linear trend\", \"resids\"]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_26\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Combine the components into a pipeline, fit it to the original time series and obtain predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = TransformedTargetForecaster(\n",
    "    steps = [\n",
    "        (\"deseasonalize\", Deseasonalizer(model=\"additive\", sp=12)),\n",
    "        (\"detrend\", Detrender(\n",
    "            forecaster=PolynomialTrendForecaster(degree=1)\n",
    "        )),\n",
    "        (\"forecast\", rf_forecaster),\n",
    "    ]\n",
    ")\n",
    "rf_pipe.fit(y_train)\n",
    "y_pred_2 = rf_pipe.predict(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Evaluate the pipeline's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_2 = mean_absolute_percentage_error(\n",
    "    y_test, y_pred_2, symmetric=False\n",
    ")\n",
    "fig, ax = plot_series(\n",
    "    y_train[\"2016\":], y_test, y_pred_2,\n",
    "    labels=[\"y_train\", \"y_test\", \"y_pred\"]\n",
    ")\n",
    "ax.set_title(f\"MAPE: {100*mape_2:.2f}%\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_27\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Evaluate the performance using expanding window cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ExpandingWindowSplitter(\n",
    "    fh=list(range(1,13)), \n",
    "    initial_window=12*5, \n",
    "    step_length=12\n",
    ")\n",
    "\n",
    "cv_df = evaluate(\n",
    "    forecaster=rf_pipe, \n",
    "    y=y, \n",
    "    cv=cv, \n",
    "    strategy=\"refit\", \n",
    "    return_data=True\n",
    ")\n",
    "\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in cv_df.iterrows():\n",
    "    print(f\"Fold {ind} ----\")\n",
    "    print(f\"Training: {row['y_train'].index.min()} - {row['y_train'].index.max()}\")\n",
    "    print(f\"Training: {row['y_test'].index.min()} - {row['y_test'].index.max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Plot the predictions from the cross-validation folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = len(cv_df)\n",
    "\n",
    "plot_series(\n",
    "    y, \n",
    "    *[cv_df[\"y_pred\"].iloc[x] for x in range(n_fold)],\n",
    "    markers=[\"o\", *[\".\"] * n_fold],\n",
    "    labels=[\"y_true\"] + [f\"cv: {x}\" for x in range(n_fold)]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_29\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Create an ensemble forecast using the RF pipeline and AutoARIMA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = EnsembleForecaster(\n",
    "    forecasters = [\n",
    "        (\"autoarima\", AutoARIMA(sp=12)),\n",
    "        (\"rf_pipe\", rf_pipe)\n",
    "    ]\n",
    ")\n",
    "ensemble.fit(y_train)\n",
    "y_pred_3 = ensemble.predict(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Evaluate the ensemble's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_3 = mean_absolute_percentage_error(\n",
    "    y_test, y_pred_3, symmetric=False\n",
    ")\n",
    "fig, ax = plot_series(\n",
    "    y_train[\"2016\":], y_test, y_pred_3,\n",
    "    labels=[\"y_train\", \"y_test\", \"y_pred\"]\n",
    ")\n",
    "ax.set_title(f\"MAPE: {100*mape_3:.2f}%\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create naive forecasts using the `NaiveForecaster`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "\n",
    "naive_fcst_last = NaiveForecaster(strategy=\"last\")\n",
    "naive_fcst_last.fit(y_train)\n",
    "y_last = naive_fcst_last.predict(fh)\n",
    "\n",
    "naive_fcst_seas = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "naive_fcst_seas.fit(y_train)\n",
    "y_seasonal_last = naive_fcst_seas.predict(fh)\n",
    "\n",
    "plot_series(\n",
    "    y_train[\"2016\":], y_test, y_last, y_seasonal_last, \n",
    "    labels=[\"y_train\", \"y_test\", \"y_pred_last\", \"y_pred_last_seas\"]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Inspect all the available models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"forecaster\", as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Forecasting with Meta's Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate with Nasdaq Data Link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:48:07.480504Z",
     "start_time": "2020-01-24T21:48:07.357239Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nasdaqdatalink\n",
    "from prophet import Prophet\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YK5hwjxe3Swf2y_zTjxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the daily gold prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:46:40.757613Z",
     "start_time": "2020-01-24T21:46:39.775269Z"
    }
   },
   "outputs": [],
   "source": [
    "df = nasdaqdatalink.get(\n",
    "    dataset=\"WGC/GOLD_DAILY_USD\",\n",
    "    start_date=\"2015-01-01\",\n",
    "    end_date=\"2019-12-31\"\n",
    ")\n",
    "\n",
    "df.plot(title=\"Daily gold prices (2015-2019)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_31\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Rename the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=False)\n",
    "df.columns = [\"ds\", \"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T18:01:13.789839Z",
     "start_time": "2019-11-26T18:01:13.780883Z"
    }
   },
   "source": [
    "4. Split the series into the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:46:41.641108Z",
     "start_time": "2020-01-24T21:46:41.630251Z"
    }
   },
   "outputs": [],
   "source": [
    "train_indices = df[\"ds\"] < \"2019-10-01\"\n",
    "df_train = df.loc[train_indices].dropna()\n",
    "df_test = (\n",
    "    df\n",
    "    .loc[~train_indices]\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create the instance of the model and fit it to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:46:45.006885Z",
     "start_time": "2020-01-24T21:46:43.293078Z"
    }
   },
   "outputs": [],
   "source": [
    "prophet = Prophet(changepoint_range=0.9)\n",
    "prophet.add_country_holidays(country_name=\"US\")\n",
    "prophet.add_seasonality(\n",
    "    name=\"monthly\", period=30.5, fourier_order=5\n",
    ")\n",
    "prophet.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Forecast the gold prices for the fourth quarter of 2019 and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:46:59.335955Z",
     "start_time": "2020-01-24T21:46:52.748232Z"
    }
   },
   "outputs": [],
   "source": [
    "df_future = prophet.make_future_dataframe(\n",
    "    periods=len(df_test), freq=\"B\"\n",
    ")\n",
    "df_pred = prophet.predict(df_future)\n",
    "prophet.plot(df_pred)\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Add changepoints to the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = prophet.plot(df_pred)\n",
    "a = add_changepoints_to_plot(\n",
    "    fig.gca(), prophet, df_pred\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_33\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet.changepoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Inspect the decomposition of the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:47:11.368924Z",
     "start_time": "2020-01-24T21:47:05.680599Z"
    }
   },
   "outputs": [],
   "source": [
    "prophet.plot_components(df_pred)\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_34\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Merge the test set with the forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:47:39.837325Z",
     "start_time": "2020-01-24T21:47:39.825475Z"
    }
   },
   "outputs": [],
   "source": [
    "SELECTED_COLS = [\n",
    "    \"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"\n",
    "]\n",
    "\n",
    "df_pred = (\n",
    "    df_pred\n",
    "    .loc[:, SELECTED_COLS]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_test = df_test.merge(df_pred, on=[\"ds\"], how=\"left\")\n",
    "df_test[\"ds\"] = pd.to_datetime(df_test[\"ds\"])\n",
    "df_test = df_test.set_index(\"ds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Plot the test values vs. predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "PLOT_COLS = [\n",
    "    \"y\", \"yhat\", \"yhat_lower\", \"yhat_upper\"\n",
    "]\n",
    "ax = sns.lineplot(data=df_test[PLOT_COLS])\n",
    "ax.fill_between(\n",
    "    df_test.index,\n",
    "    df_test[\"yhat_lower\"],\n",
    "    df_test[\"yhat_upper\"],\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title=\"Gold Price - actual vs. predicted\",\n",
    "    xlabel=\"Date\",\n",
    "    ylabel=\"Gold Price ($)\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_35\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.diagnostics import (cross_validation, \n",
    "                                 performance_metrics)\n",
    "from prophet.plot import plot_cross_validation_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run Prophet's cross-validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = cross_validation(\n",
    "    prophet, \n",
    "    initial=\"756 days\", \n",
    "    period=\"60 days\", \n",
    "    horizon = \"60 days\"\n",
    ")\n",
    "\n",
    "df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv[\"cutoff\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate the aggregated performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = performance_metrics(df_cv)\n",
    "df_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Plot the MAPE score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cross_validation_metric(df_cv, metric=\"mape\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_38\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 AutoML for time series forecasting with PyCaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nasdaqdatalink\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the monthly US unemployment rate from years 2010-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    nasdaqdatalink.get(dataset=\"FRED/UNRATENSA\", \n",
    "                       start_date=\"2010-01-01\", \n",
    "                       end_date=\"2019-12-31\")\n",
    "    .rename(columns={\"Value\": \"unemp_rate\"})\n",
    ")\n",
    "df.plot(title=\"Unemployment rate (US) - monthly\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "from pycaret.time_series import TSForecastingExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set up the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = TSForecastingExperiment()\n",
    "exp.setup(df, fh=6, fold=5, session_id=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Explore the time series using visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(\n",
    "    plot=\"diagnostics\", \n",
    "    fig_kwargs={\"height\": 800, \"width\": 1000}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot=\"cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot=\"ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot=\"acf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot=\"decomp_stl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot=\"periodogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot=\"fft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run statistical tests on the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.check_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.check_stats(test=\"summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Find the five best fitting pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipelines = exp.compare_models(\n",
    "    sort=\"MAPE\", turbo=False, n_select=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover the DataFrame with the metrics\n",
    "compare_metrics_base = exp.pull()\n",
    "compare_metrics_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the available models\n",
    "exp.models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Tune the best pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipelines_tuned = [exp.tune_model(model) for model in best_pipelines]\n",
    "best_pipelines_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Blend the 5 tuned pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_model = exp.blend_models(\n",
    "    best_pipelines_tuned, method=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Create the predictions using the blended model and plot the forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = exp.predict_model(blended_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(estimator=blended_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Finalize the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = exp.finalize_model(blended_model)\n",
    "exp.plot_model(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = exp.predict_model(final_model)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "0117835dafdb051235b33d006a7ad155411608685e1d44af6fb551f6db3e7774"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
