{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OEACZptdHC7"
   },
   "source": [
    "Please run those two cells before running the Notebook!\n",
    "\n",
    "As those plotting settings are standard throughout the book, we do not show them in the book every time we plot something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:48:06.120195Z",
     "start_time": "2020-01-29T10:48:05.814125Z"
    },
    "id": "_JscbREmdHC-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T10:48:13.141309Z",
     "start_time": "2020-01-29T10:48:13.137453Z"
    },
    "id": "r6OEEsWTdHDB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "# FIX: Use the official public API path from pandas.errors\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "# feel free to modify, for example, change the context to \"notebook\"\n",
    "sns.set_theme(context=\"talk\", style=\"whitegrid\", \n",
    "              palette=\"colorblind\", color_codes=True, \n",
    "              rc={\"figure.figsize\": [12, 8]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 - ML-based Approaches to Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Validation methods for time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import nasdaqdatalink\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YK5hwjxe3Swf2y_zTjxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the monthly US unemployment rate from years 2010-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: Install the pandas-datareader library\n",
    "!pip install pandas-datareader\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# FIX: Download the data directly from FRED using its series ID \"UNRATENSA\"\n",
    "df = (\n",
    "    web.DataReader(name=\"UNRATENSA\", \n",
    "                   data_source=\"fred\",\n",
    "                   start=\"2010-01-01\",\n",
    "                   end=\"2019-12-31\")\n",
    "    .rename(columns={\"UNRATENSA\": \"unemp_rate\"})\n",
    ")\n",
    "\n",
    "df.plot(title=\"Unemployment rate (US) - monthly\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create simple features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"linear_trend\"] = range(len(df))\n",
    "df[\"month\"] = df.index.month\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use one-hot encoding for the month feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dummies = pd.get_dummies(\n",
    "    df[\"month\"], drop_first=True, prefix=\"month\"\n",
    ")\n",
    "\n",
    "df = df.join(month_dummies) \\\n",
    "       .drop(columns=[\"month\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Separate the target from the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(\"unemp_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Define the expanding window walk-forward validation and print the indices of the folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanding_cv = TimeSeriesSplit(n_splits=5, test_size=12)\n",
    "\n",
    "for fold, (train_ind, valid_ind) in enumerate(expanding_cv.split(X)):\n",
    "    print(f\"Fold {fold} ----\")\n",
    "    print(f\"Train indices: {train_ind}\")\n",
    "    print(f\"Valid indices: {valid_ind}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Evaluate the model's performance using the expanding window validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [] \n",
    "\n",
    "for train_ind, valid_ind in expanding_cv.split(X):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X.iloc[train_ind], y.iloc[train_ind])\n",
    "    y_pred = lr.predict(X.iloc[valid_ind])\n",
    "    scores.append(\n",
    "        mean_absolute_percentage_error(y.iloc[valid_ind], y_pred)\n",
    "    )\n",
    "\n",
    "print(f\"Scores: {scores}\")\n",
    "print(f\"Avg. score: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_validate(\n",
    "    LinearRegression(), \n",
    "    X, y, \n",
    "    cv=expanding_cv, \n",
    "    scoring=[\"neg_mean_absolute_percentage_error\", \n",
    "             \"neg_root_mean_squared_error\"]\n",
    ")\n",
    "pd.DataFrame(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Define the sliding window validation and print the indices of the folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_cv = TimeSeriesSplit(\n",
    "    n_splits=5, test_size=12, max_train_size=60\n",
    ")\n",
    "\n",
    "for fold, (train_ind, valid_ind) in enumerate(sliding_cv.split(X)):\n",
    "    print(f\"Fold {fold} ----\")\n",
    "    print(f\"Train indices: {train_ind}\")\n",
    "    print(f\"Valid indices: {valid_ind}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Evaluate the model's performance using the sliding window validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_validate(\n",
    "    LinearRegression(), \n",
    "    X, y, \n",
    "    cv=sliding_cv, \n",
    "    scoring=[\"neg_mean_absolute_percentage_error\", \n",
    "             \"neg_root_mean_squared_error\"]\n",
    ")\n",
    "pd.DataFrame(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-1 * cv_scores[\"test_neg_mean_absolute_percentage_error\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Feature engineering for time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: Install the scikit-lego library\n",
    "!pip install scikit-lego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklego.preprocessing import RepeatingBasisFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary change for this recipe\n",
    "sns.set_palette([\"grey\", \"blue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generate a time series with repeating patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "range_of_dates = pd.date_range(start=\"2017-01-01\", \n",
    "                               end=\"2019-12-31\")\n",
    "X = pd.DataFrame(index=range_of_dates)\n",
    "\n",
    "X[\"day_nr\"] = range(len(X))\n",
    "X[\"day_of_year\"] = X.index.day_of_year\n",
    "\n",
    "signal_1 = 2 + 3 * np.sin(X[\"day_nr\"] / 365 * 2 * np.pi)\n",
    "signal_2 = 2 * np.sin(X[\"day_nr\"] / 365 * 4 * np.pi + 365/2)\n",
    "noise = np.random.normal(0, 0.81, len(X))\n",
    "\n",
    "y = signal_1 + signal_2 + noise\n",
    "y.name = \"y\"\n",
    "\n",
    "y.plot(title=\"Generated time series\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Store the time series in a new DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = y.to_frame()\n",
    "results_df.columns = [\"y_true\"]\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Encode the month information as dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = pd.get_dummies(\n",
    "    X.index.month, drop_first=True, prefix=\"month\"\n",
    ")\n",
    "X_1.index = X.index\n",
    "X_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fit a linear regression model and plot the in-sample prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LinearRegression().fit(X_1, y)\n",
    "\n",
    "results_df[\"y_pred_1\"] = model_1.predict(X_1)\n",
    "(\n",
    "    results_df[[\"y_true\", \"y_pred_1\"]]\n",
    "    .plot(title=\"Fit using month dummies\")\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Define functions used for creating the cyclical encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_transformer(period):\n",
    "\treturn FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "\n",
    "def cos_transformer(period):\n",
    "\treturn FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Encode the month and day information using cyclical encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X.copy()\n",
    "X_2[\"month\"] = X_2.index.month\n",
    "\n",
    "X_2[\"month_sin\"] = sin_transformer(12).fit_transform(X_2)[\"month\"]\n",
    "X_2[\"month_cos\"] = cos_transformer(12).fit_transform(X_2)[\"month\"]\n",
    "\n",
    "X_2[\"day_sin\"] = (\n",
    "    sin_transformer(365).fit_transform(X_2)[\"day_of_year\"]\n",
    ")\n",
    "X_2[\"day_cos\"] = (\n",
    "    cos_transformer(365).fit_transform(X_2)[\"day_of_year\"]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, sharex=True, figsize=(16,8))\n",
    "X_2[[\"month_sin\", \"month_cos\"]].plot(ax=ax[0])\n",
    "ax[0].legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "X_2[[\"day_sin\", \"day_cos\"]].plot(ax=ax[1])\n",
    "ax[1].legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.suptitle(\"Cyclical encoding with sine/cosine transformation\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_2[X_2.index.year == 2017]\n",
    "    .plot(\n",
    "        kind=\"scatter\", \n",
    "        x=\"month_sin\", \n",
    "        y=\"month_cos\", \n",
    "        figsize=(8, 8),\n",
    "        title=\"Cyclical encoding using sine/cosine transformations\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Fit a model using the daily sine/cosine features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_2[[\"day_sin\", \"day_cos\"]]\n",
    "\n",
    "model_2 = LinearRegression().fit(X_2, y)\n",
    "\n",
    "results_df[\"y_pred_2\"] = model_2.predict(X_2)\n",
    "(\n",
    "    results_df[[\"y_true\", \"y_pred_2\"]]\n",
    "    .plot(title=\"Fit using sine/cosine features\")\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Create features using the radial basis functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = RepeatingBasisFunction(n_periods=12,\n",
    "                             column=\"day_of_year\",\n",
    "                             input_range=(1,365),\n",
    "                             remainder=\"drop\")\n",
    "rbf.fit(X)\n",
    "X_3 = pd.DataFrame(index=X.index, \n",
    "                   data=rbf.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3.plot(subplots=True, sharex=True, \n",
    "         title=\"Radial Basis Functions\", \n",
    "         legend=False, figsize=(14, 10))\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Fit a model using the RBF features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = LinearRegression().fit(X_3, y)\n",
    "\n",
    "results_df[\"y_pred_3\"] = model_3.predict(X_3)\n",
    "(\n",
    "    results_df[[\"y_true\", \"y_pred_3\"]]\n",
    "    .plot(title=\"Fit using RBF features\")\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: Install the tsfresh library\n",
    "!pip install tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.date import DateTimeFeatures\n",
    "\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import settings\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extract the datetime-features using `sktime`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_features = DateTimeFeatures(\n",
    "    ts_freq=\"D\", feature_scope=\"comprehensive\"\n",
    ")\n",
    "features_df_1 = dt_features.fit_transform(y)\n",
    "features_df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepare the dataset for feature extraction with `tsfresh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = y.to_frame().reset_index(drop=False)\n",
    "df.columns = [\"date\", \"y\"]\n",
    "df[\"series_id\"] = \"a\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a rolled-up DataFrame for feature extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled = roll_time_series(\n",
    "    df, column_id=\"series_id\", column_sort=\"date\",\n",
    "    max_timeshift=30, min_timeshift=7\n",
    ").drop(columns=[\"series_id\"])\n",
    "df_rolled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Extract the minimal set of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_minimal = settings.MinimalFCParameters() \n",
    "settings_minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df_2 = extract_features(\n",
    "    df_rolled, column_id=\"id\", \n",
    "    column_sort=\"date\", \n",
    "    default_fc_parameters=settings_minimal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Clean up the index and inspect the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df_2 = (\n",
    "    features_df_2\n",
    "    .set_index(\n",
    "        features_df_2.index.map(lambda x: x[1]), drop=True\n",
    "    )\n",
    ")\n",
    "features_df_2.index.name = \"last_date\"\n",
    "features_df_2.head(25).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Time series forecasting as reduced regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nasdaqdatalink\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the monthly US unemployment rate from years 2010-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (\n",
    "    nasdaqdatalink.get(dataset=\"FRED/UNRATENSA\", \n",
    "                       start_date=\"2010-01-01\", \n",
    "                       end_date=\"2019-12-31\")\n",
    "    .rename(columns={\"Value\": \"unemp_rate\"})\n",
    ")\n",
    "y.index = y.index.to_period(freq=\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils.plotting import plot_series\n",
    "from sktime.forecasting.model_selection import (\n",
    "    temporal_train_test_split, ExpandingWindowSplitter\n",
    ")\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.compose import (\n",
    "    make_reduction, TransformedTargetForecaster, \n",
    "    EnsembleForecaster\n",
    ")\n",
    "from sktime.performance_metrics.forecasting import (\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sktime.transformations.series.detrend import (\n",
    "    Deseasonalizer, Detrender\n",
    ")\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.forecasting.model_evaluation import evaluate\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split the time series into training and tests sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = temporal_train_test_split(\n",
    "    y, test_size=12\n",
    ")\n",
    "plot_series(\n",
    "    y_train, y_test, \n",
    "    labels=[\"y_train\", \"y_test\"]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_22\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Set the forecast horizon to 12 months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "fh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Instantiate the reduced regression model, fit it to the data and create predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(random_state=42)\n",
    "rf_forecaster = make_reduction(\n",
    "    estimator=regressor, \n",
    "    strategy=\"recursive\", \n",
    "    window_length=12\n",
    ")\n",
    "rf_forecaster.fit(y_train)\n",
    "y_pred_1 = rf_forecaster.predict(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evaluate the performance of the forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_1 = mean_absolute_percentage_error(\n",
    "    y_test, y_pred_1, symmetric=False\n",
    ")\n",
    "fig, ax = plot_series(\n",
    "    y_train[\"2016\":], y_test, y_pred_1,\n",
    "    labels=[\"y_train\", \"y_test\", \"y_pred\"]\n",
    ")\n",
    "ax.set_title(f\"MAPE: {100*mape_1:.2f}%\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_23\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Deseasonalize the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasonalizer = Deseasonalizer(model=\"additive\", sp=12)\n",
    "y_deseas = deseasonalizer.fit_transform(y_train)\n",
    "plot_series(\n",
    "    y_train, y_deseas, \n",
    "    labels=[\"y_train\", \"y_deseas\"]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(\n",
    "    deseasonalizer.seasonal_, \n",
    "    labels=[\"seasonal_component\"]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Detrend the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = PolynomialTrendForecaster(degree=1)\n",
    "transformer = Detrender(forecaster=forecaster)\n",
    "y_detrend = transformer.fit_transform(y_deseas)\n",
    "\n",
    "# in-sample predictions\n",
    "forecaster = PolynomialTrendForecaster(degree=1)\n",
    "y_in_sample = (\n",
    "    forecaster\n",
    "    .fit(y_deseas)\n",
    "    .predict(fh=-np.arange(len(y_deseas)))\n",
    ")\n",
    "\n",
    "plot_series(\n",
    "    y_deseas, y_in_sample, y_detrend, \n",
    "    labels=[\"y_deseas\", \"linear trend\", \"resids\"]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_26\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Combine the components into a pipeline, fit it to the original time series and obtain predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = TransformedTargetForecaster(\n",
    "    steps = [\n",
    "        (\"deseasonalize\", Deseasonalizer(model=\"additive\", sp=12)),\n",
    "        (\"detrend\", Detrender(\n",
    "            forecaster=PolynomialTrendForecaster(degree=1)\n",
    "        )),\n",
    "        (\"forecast\", rf_forecaster),\n",
    "    ]\n",
    ")\n",
    "rf_pipe.fit(y_train)\n",
    "y_pred_2 = rf_pipe.predict(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Evaluate the pipeline's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_2 = mean_absolute_percentage_error(\n",
    "    y_test, y_pred_2, symmetric=False\n",
    ")\n",
    "fig, ax = plot_series(\n",
    "    y_train[\"2016\":], y_test, y_pred_2,\n",
    "    labels=[\"y_train\", \"y_test\", \"y_pred\"]\n",
    ")\n",
    "ax.set_title(f\"MAPE: {100*mape_2:.2f}%\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_27\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Evaluate the performance using expanding window cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ExpandingWindowSplitter(\n",
    "    fh=list(range(1,13)), \n",
    "    initial_window=12*5, \n",
    "    step_length=12\n",
    ")\n",
    "\n",
    "cv_df = evaluate(\n",
    "    forecaster=rf_pipe, \n",
    "    y=y, \n",
    "    cv=cv, \n",
    "    strategy=\"refit\", \n",
    "    return_data=True\n",
    ")\n",
    "\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in cv_df.iterrows():\n",
    "    print(f\"Fold {ind} ----\")\n",
    "    print(f\"Training: {row['y_train'].index.min()} - {row['y_train'].index.max()}\")\n",
    "    print(f\"Training: {row['y_test'].index.min()} - {row['y_test'].index.max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Plot the predictions from the cross-validation folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = len(cv_df)\n",
    "\n",
    "plot_series(\n",
    "    y, \n",
    "    *[cv_df[\"y_pred\"].iloc[x] for x in range(n_fold)],\n",
    "    markers=[\"o\", *[\".\"] * n_fold],\n",
    "    labels=[\"y_true\"] + [f\"cv: {x}\" for x in range(n_fold)]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_29\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Create an ensemble forecast using the RF pipeline and AutoARIMA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = EnsembleForecaster(\n",
    "    forecasters = [\n",
    "        (\"autoarima\", AutoARIMA(sp=12)),\n",
    "        (\"rf_pipe\", rf_pipe)\n",
    "    ]\n",
    ")\n",
    "ensemble.fit(y_train)\n",
    "y_pred_3 = ensemble.predict(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Evaluate the ensemble's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_3 = mean_absolute_percentage_error(\n",
    "    y_test, y_pred_3, symmetric=False\n",
    ")\n",
    "fig, ax = plot_series(\n",
    "    y_train[\"2016\":], y_test, y_pred_3,\n",
    "    labels=[\"y_train\", \"y_test\", \"y_pred\"]\n",
    ")\n",
    "ax.set_title(f\"MAPE: {100*mape_3:.2f}%\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create naive forecasts using the `NaiveForecaster`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "\n",
    "naive_fcst_last = NaiveForecaster(strategy=\"last\")\n",
    "naive_fcst_last.fit(y_train)\n",
    "y_last = naive_fcst_last.predict(fh)\n",
    "\n",
    "naive_fcst_seas = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "naive_fcst_seas.fit(y_train)\n",
    "y_seasonal_last = naive_fcst_seas.predict(fh)\n",
    "\n",
    "plot_series(\n",
    "    y_train[\"2016\":], y_test, y_last, y_seasonal_last, \n",
    "    labels=[\"y_train\", \"y_test\", \"y_pred_last\", \"y_pred_last_seas\"]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Inspect all the available models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"forecaster\", as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Forecasting with Meta's Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate with Nasdaq Data Link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:48:07.480504Z",
     "start_time": "2020-01-24T21:48:07.357239Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nasdaqdatalink\n",
    "from prophet import Prophet\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YK5hwjxe3Swf2y_zTjxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the daily gold prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:46:40.757613Z",
     "start_time": "2020-01-24T21:46:39.775269Z"
    }
   },
   "outputs": [],
   "source": [
    "df = nasdaqdatalink.get(\n",
    "    dataset=\"WGC/GOLD_DAILY_USD\",\n",
    "    start_date=\"2015-01-01\",\n",
    "    end_date=\"2019-12-31\"\n",
    ")\n",
    "\n",
    "df.plot(title=\"Daily gold prices (2015-2019)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_31\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Rename the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=False)\n",
    "df.columns = [\"ds\", \"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T18:01:13.789839Z",
     "start_time": "2019-11-26T18:01:13.780883Z"
    }
   },
   "source": [
    "4. Split the series into the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:46:41.641108Z",
     "start_time": "2020-01-24T21:46:41.630251Z"
    }
   },
   "outputs": [],
   "source": [
    "train_indices = df[\"ds\"] < \"2019-10-01\"\n",
    "df_train = df.loc[train_indices].dropna()\n",
    "df_test = (\n",
    "    df\n",
    "    .loc[~train_indices]\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create the instance of the model and fit it to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:46:45.006885Z",
     "start_time": "2020-01-24T21:46:43.293078Z"
    }
   },
   "outputs": [],
   "source": [
    "prophet = Prophet(changepoint_range=0.9)\n",
    "prophet.add_country_holidays(country_name=\"US\")\n",
    "prophet.add_seasonality(\n",
    "    name=\"monthly\", period=30.5, fourier_order=5\n",
    ")\n",
    "prophet.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Forecast the gold prices for the fourth quarter of 2019 and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:46:59.335955Z",
     "start_time": "2020-01-24T21:46:52.748232Z"
    }
   },
   "outputs": [],
   "source": [
    "df_future = prophet.make_future_dataframe(\n",
    "    periods=len(df_test), freq=\"B\"\n",
    ")\n",
    "df_pred = prophet.predict(df_future)\n",
    "prophet.plot(df_pred)\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Add changepoints to the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = prophet.plot(df_pred)\n",
    "a = add_changepoints_to_plot(\n",
    "    fig.gca(), prophet, df_pred\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_33\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet.changepoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Inspect the decomposition of the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:47:11.368924Z",
     "start_time": "2020-01-24T21:47:05.680599Z"
    }
   },
   "outputs": [],
   "source": [
    "prophet.plot_components(df_pred)\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_34\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Merge the test set with the forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:47:39.837325Z",
     "start_time": "2020-01-24T21:47:39.825475Z"
    }
   },
   "outputs": [],
   "source": [
    "SELECTED_COLS = [\n",
    "    \"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"\n",
    "]\n",
    "\n",
    "df_pred = (\n",
    "    df_pred\n",
    "    .loc[:, SELECTED_COLS]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_test = df_test.merge(df_pred, on=[\"ds\"], how=\"left\")\n",
    "df_test[\"ds\"] = pd.to_datetime(df_test[\"ds\"])\n",
    "df_test = df_test.set_index(\"ds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Plot the test values vs. predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "PLOT_COLS = [\n",
    "    \"y\", \"yhat\", \"yhat_lower\", \"yhat_upper\"\n",
    "]\n",
    "ax = sns.lineplot(data=df_test[PLOT_COLS])\n",
    "ax.fill_between(\n",
    "    df_test.index,\n",
    "    df_test[\"yhat_lower\"],\n",
    "    df_test[\"yhat_upper\"],\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title=\"Gold Price - actual vs. predicted\",\n",
    "    xlabel=\"Date\",\n",
    "    ylabel=\"Gold Price ($)\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_35\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.diagnostics import (cross_validation, \n",
    "                                 performance_metrics)\n",
    "from prophet.plot import plot_cross_validation_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run Prophet's cross-validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = cross_validation(\n",
    "    prophet, \n",
    "    initial=\"756 days\", \n",
    "    period=\"60 days\", \n",
    "    horizon = \"60 days\"\n",
    ")\n",
    "\n",
    "df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv[\"cutoff\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate the aggregated performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = performance_metrics(df_cv)\n",
    "df_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Plot the MAPE score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cross_validation_metric(df_cv, metric=\"mape\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "# plt.savefig(\"images/figure_7_38\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 AutoML for time series forecasting with PyCaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries and authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nasdaqdatalink\n",
    "\n",
    "nasdaqdatalink.ApiConfig.api_key = \"YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the monthly US unemployment rate from years 2010-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    nasdaqdatalink.get(dataset=\"FRED/UNRATENSA\", \n",
    "                       start_date=\"2010-01-01\", \n",
    "                       end_date=\"2019-12-31\")\n",
    "    .rename(columns={\"Value\": \"unemp_rate\"})\n",
    ")\n",
    "df.plot(title=\"Unemployment rate (US) - monthly\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "from pycaret.time_series import TSForecastingExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set up the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = TSForecastingExperiment()\n",
    "exp.setup(df, fh=6, fold=5, session_id=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Explore the time series using visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(\n",
    "    plot=\"diagnostics\", \n",
    "    fig_kwargs={\"height\": 800, \"width\": 1000}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot=\"cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot=\"ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot=\"acf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot=\"decomp_stl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot=\"periodogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot=\"fft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run statistical tests on the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.check_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.check_stats(test=\"summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Find the five best fitting pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipelines = exp.compare_models(\n",
    "    sort=\"MAPE\", turbo=False, n_select=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover the DataFrame with the metrics\n",
    "compare_metrics_base = exp.pull()\n",
    "compare_metrics_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the available models\n",
    "exp.models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Tune the best pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipelines_tuned = [exp.tune_model(model) for model in best_pipelines]\n",
    "best_pipelines_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Blend the 5 tuned pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_model = exp.blend_models(\n",
    "    best_pipelines_tuned, method=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Create the predictions using the blended model and plot the forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = exp.predict_model(blended_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(estimator=blended_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Finalize the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = exp.finalize_model(blended_model)\n",
    "exp.plot_model(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = exp.predict_model(final_model)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "0117835dafdb051235b33d006a7ad155411608685e1d44af6fb551f6db3e7774"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
